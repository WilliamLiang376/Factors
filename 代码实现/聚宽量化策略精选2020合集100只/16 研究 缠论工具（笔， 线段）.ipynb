{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 风险及免责提示：该策略由聚宽用户在聚宽社区分享，仅供学习交流使用。\n",
    "# 原文一般包含策略说明，如有疑问请到原文和作者交流讨论。\n",
    "# 原文网址：https://www.joinquant.com/view/community/detail/26842\n",
    "# 标题：缠论工具（笔， 线段）\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import talib\n",
    "\n",
    "from enum import Enum \n",
    "\n",
    "from numpy.lib.recfunctions import append_fields\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "class InclusionType(Enum):\n",
    "    # output: 0 = no inclusion, 1 = first contains second, 2 second contains first\n",
    "    noInclusion = 0\n",
    "    firstCsecond = 2\n",
    "    secondCfirst = 3\n",
    "    \n",
    "class TopBotType(Enum):\n",
    "    noTopBot = 0\n",
    "    bot2top = 0.5\n",
    "    top = 1\n",
    "    top2bot = -0.5\n",
    "    bot = -1\n",
    "\n",
    "    @classmethod\n",
    "    def reverse(cls, tp):\n",
    "        if tp == cls.top:\n",
    "            return cls.bot\n",
    "        elif tp == cls.bot:\n",
    "            return cls.top\n",
    "        elif tp == cls.top2bot:\n",
    "            return cls.bot2top\n",
    "        elif tp == cls.bot2top:\n",
    "            return cls.top2bot\n",
    "        else:\n",
    "            return cls.noTopBot\n",
    "    \n",
    "    @classmethod\n",
    "    def value2type(cls, val):\n",
    "        if val == 0:\n",
    "            return cls.noTopBot\n",
    "        elif val == 0.5:\n",
    "            return cls.bot2top\n",
    "        elif val == 1:\n",
    "            return cls.top\n",
    "        elif val == -0.5:\n",
    "            return cls.top2bot\n",
    "        elif val == -1:\n",
    "            return cls.bot\n",
    "        else:\n",
    "            return cls.noTopBot\n",
    "\n",
    "\n",
    "######################## common method ###############################\n",
    "\n",
    "def float_less(a, b):\n",
    "    return a < b and not np.isclose(a, b)\n",
    "\n",
    "def float_more(a, b):\n",
    "    return a > b and not np.isclose(a, b)\n",
    "\n",
    "def float_less_equal(a, b):\n",
    "    return a < b or np.isclose(a, b)\n",
    "\n",
    "def float_more_equal(a, b):\n",
    "    return a > b or np.isclose(a, b)\n",
    "\n",
    "######################## kBarprocessor #############################\n",
    "GOLDEN_RATIO = 0.618\n",
    "MIN_PRICE_UNIT=0.01\n",
    "        \n",
    "FEN_BI_COLUMNS = ['date', 'close', 'high', 'low', 'tb', 'real_loc']\n",
    "FEN_DUAN_COLUMNS =  ['date', 'close', 'high', 'low', 'chan_price', 'tb', 'xd_tb', 'real_loc']\n",
    "\n",
    "def gap_range_func(a):\n",
    "    if float_more(a['low'] - a['high_s1'], MIN_PRICE_UNIT):\n",
    "        return [a['high_s1'], a['low']]\n",
    "    elif float_less(a['high'] - a['low_s1'], -MIN_PRICE_UNIT):\n",
    "        return [a['high'], a['low_s1']]\n",
    "    else:\n",
    "        return [0, 0]\n",
    "\n",
    "def get_previous_loc(loc, working_df):\n",
    "    i = loc - 1\n",
    "    while i >= 0:\n",
    "        if working_df[i]['tb'] == TopBotType.top.value or working_df[i]['tb'] == TopBotType.bot.value:\n",
    "            return i\n",
    "        else:\n",
    "            i = i - 1\n",
    "    return None\n",
    "\n",
    "def get_next_loc(loc, working_df):\n",
    "    i = loc + 1\n",
    "    while i < len(working_df):\n",
    "        if working_df[i]['tb'] == TopBotType.top.value or working_df[i]['tb'] == TopBotType.bot.value:\n",
    "            return i\n",
    "        else:\n",
    "            i = i + 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KBarChan(object):\n",
    "    '''\n",
    "    This is a rewrite of KBarProcessor, that one is too slow!! we used pandas dataframe, we should use numpy array!\n",
    "    df=False flag is used here\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, kDf, isdebug=False, clean_standardzed=False):\n",
    "        self.isdebug = isdebug\n",
    "        self.clean_standardzed = clean_standardzed\n",
    "        self.kDataFrame_origin = kDf\n",
    "        self.kDataFrame_standardized = copy.deepcopy(kDf)\n",
    "        \n",
    "        self.kDataFrame_standardized = append_fields(self.kDataFrame_standardized, \n",
    "                                                     ['new_high', 'new_low', 'trend_type', 'real_loc'],\n",
    "                                                     [\n",
    "                                                         [0]*len(self.kDataFrame_standardized),\n",
    "                                                         [0]*len(self.kDataFrame_standardized),\n",
    "                                                         [TopBotType.noTopBot.value]*len(self.kDataFrame_standardized),\n",
    "                                                         [i for i in range(len(self.kDataFrame_standardized))]\n",
    "                                                     ],\n",
    "                                                     [float, float, int, int],\n",
    "                                                     usemask=False)\n",
    "        self.kDataFrame_marked = None\n",
    "        self.kDataFrame_xd = None\n",
    "        self.gap_XD = []\n",
    "        self.previous_skipped_idx = []\n",
    "        self.previous_with_xd_gap = False # help to check current gap as XD\n",
    "        if self.isdebug:\n",
    "            print(\"self.kDataFrame_origin head:{0}\".format(self.kDataFrame_origin[:10]))\n",
    "            print(\"self.kDataFrame_origin tail:{0}\".format(self.kDataFrame_origin[-10:]))\n",
    "        \n",
    "    def checkInclusive(self, first, second):\n",
    "        # output: 0 = no inclusion, 1 = first contains second, 2 second contains first\n",
    "        isInclusion = InclusionType.noInclusion\n",
    "        first_high = first['high'] if first['new_high']==0 else first['new_high']\n",
    "        second_high = second['high'] if second['new_high']==0 else second['new_high']\n",
    "        first_low = first['low'] if first['new_low']==0 else first['new_low']\n",
    "        second_low = second['low'] if second['new_low']==0 else second['new_low']\n",
    "        \n",
    "        if float_less_equal(first_high, second_high) and float_more_equal(first_low, second_low):\n",
    "            isInclusion = InclusionType.firstCsecond\n",
    "        elif float_more_equal(first_high, second_high) and float_less_equal(first_low, second_low):\n",
    "            isInclusion = InclusionType.secondCfirst\n",
    "        return isInclusion\n",
    "    \n",
    "    def isBullType(self, first, second): \n",
    "        # this is assuming first second aren't inclusive\n",
    "        f_high = first['high'] if first['new_high']==0 else first['new_high']\n",
    "        s_high = second['high'] if second['new_high']==0 else second['new_high']\n",
    "        return TopBotType.bot2top if float_less(f_high, s_high) else TopBotType.top2bot\n",
    "            \n",
    "        \n",
    "    def standardize(self, initial_state=TopBotType.noTopBot):\n",
    "        # 1. We need to make sure we start with first two K-bars without inclusive relationship\n",
    "        # drop the first if there is inclusion, and check again\n",
    "        if initial_state == TopBotType.top or initial_state == TopBotType.bot:\n",
    "            # given the initial state, make the first two bars non-inclusive, \n",
    "            # the first bar is confirmed as pivot, anything followed with inclusive relation \n",
    "            # will be merged into the first bar\n",
    "            while len(self.kDataFrame_standardized) > 2:\n",
    "                first_Elem = self.kDataFrame_standardized[0]\n",
    "                second_Elem = self.kDataFrame_standardized[1]\n",
    "                if self.checkInclusive(first_Elem, second_Elem) != InclusionType.noInclusion:\n",
    "                    if initial_state == TopBotType.bot:\n",
    "                        self.kDataFrame_standardized[0]['new_high'] = second_Elem['high']\n",
    "                        self.kDataFrame_standardized[0]['new_low'] = first_Elem['low']\n",
    "                    elif initial_state == TopBotType.top:\n",
    "                        self.kDataFrame_standardized[0]['new_high'] = first_Elem['high']\n",
    "                        self.kDataFrame_standardized[0]['new_low'] = second_Elem['low']\n",
    "                    self.kDataFrame_standardized=np.delete(self.kDataFrame_standardized, 1, axis=0)\n",
    "                else:\n",
    "                    self.kDataFrame_standardized[0]['new_high'] = first_Elem['high']\n",
    "                    self.kDataFrame_standardized[0]['new_low'] = first_Elem['low']\n",
    "                    break                    \n",
    "        else:\n",
    "            while len(self.kDataFrame_standardized) > 2:\n",
    "                first_Elem = self.kDataFrame_standardized[0]\n",
    "                second_Elem = self.kDataFrame_standardized[1]\n",
    "                if self.checkInclusive(first_Elem, second_Elem) != InclusionType.noInclusion:\n",
    "                    self.kDataFrame_standardized=np.delete(self.kDataFrame_standardized, 0, axis=0)\n",
    "                else:\n",
    "                    self.kDataFrame_standardized[0]['new_high'] = first_Elem['high']\n",
    "                    self.kDataFrame_standardized[0]['new_low'] = first_Elem['low']\n",
    "                    break\n",
    "\n",
    "\n",
    "        # 2. loop through the whole data set and process inclusive relationship\n",
    "        pastElemIdx = 0\n",
    "        firstElemIdx = pastElemIdx+1\n",
    "        secondElemIdx = firstElemIdx+1\n",
    "        high='high'\n",
    "        low='low'\n",
    "        new_high = 'new_high'\n",
    "        new_low = 'new_low'\n",
    "        trend_type = 'trend_type'\n",
    "        \n",
    "        while secondElemIdx < len(self.kDataFrame_standardized): # xrange\n",
    "            pastElem = self.kDataFrame_standardized[pastElemIdx]\n",
    "            firstElem = self.kDataFrame_standardized[firstElemIdx]\n",
    "            secondElem = self.kDataFrame_standardized[secondElemIdx]\n",
    "            inclusion_type = self.checkInclusive(firstElem, secondElem)\n",
    "            if inclusion_type != InclusionType.noInclusion:\n",
    "                trend = firstElem[trend_type] if firstElem[trend_type]!=TopBotType.noTopBot.value else self.isBullType(pastElem, firstElem).value\n",
    "                compare_func = max if np.isclose(trend, TopBotType.bot2top.value) else min\n",
    "                if inclusion_type == InclusionType.firstCsecond:\n",
    "                    self.kDataFrame_standardized[secondElemIdx][new_high]=compare_func(firstElem[high] if firstElem[new_high]==0 else firstElem[new_high], secondElem[high] if secondElem[new_high]==0 else secondElem[new_high])\n",
    "                    self.kDataFrame_standardized[secondElemIdx][new_low]=compare_func(firstElem[low] if firstElem[new_low]==0 else firstElem[new_low], secondElem[low] if secondElem[new_low]==0 else secondElem[new_low])\n",
    "                    self.kDataFrame_standardized[secondElemIdx][trend_type] = trend\n",
    "                    self.kDataFrame_standardized[firstElemIdx][new_high]=0\n",
    "                    self.kDataFrame_standardized[firstElemIdx][new_low]=0\n",
    "                    ############ manage index for next round ###########\n",
    "                    firstElemIdx = secondElemIdx\n",
    "                    secondElemIdx += 1\n",
    "                else:\n",
    "                    self.kDataFrame_standardized[firstElemIdx][new_high]=compare_func(firstElem[high] if firstElem[new_high]==0 else firstElem[new_high], secondElem[high] if secondElem[new_high]==0 else secondElem[new_high])\n",
    "                    self.kDataFrame_standardized[firstElemIdx][new_low]=compare_func(firstElem[low] if firstElem[new_low]==0 else firstElem[new_low], secondElem[low] if secondElem[new_low]==0 else secondElem[new_low])                        \n",
    "                    self.kDataFrame_standardized[firstElemIdx][trend_type]=trend\n",
    "                    self.kDataFrame_standardized[secondElemIdx][new_high]=0\n",
    "                    self.kDataFrame_standardized[secondElemIdx][new_low]=0\n",
    "                    ############ manage index for next round ###########\n",
    "                    secondElemIdx += 1\n",
    "            else:\n",
    "                if firstElem[new_high] == 0: \n",
    "                    self.kDataFrame_standardized[firstElemIdx][new_high] = firstElem[high]\n",
    "                if firstElem[new_low] == 0: \n",
    "                    self.kDataFrame_standardized[firstElemIdx][new_low] = firstElem[low]\n",
    "                if secondElem[new_high] == 0: \n",
    "                    self.kDataFrame_standardized[secondElemIdx][new_high] = secondElem[high]\n",
    "                if secondElem[new_low] == 0: \n",
    "                    self.kDataFrame_standardized[secondElemIdx][new_low] = secondElem[low]\n",
    "                ############ manage index for next round ###########\n",
    "                pastElemIdx = firstElemIdx\n",
    "                firstElemIdx = secondElemIdx\n",
    "                secondElemIdx += 1\n",
    "                \n",
    "        # clean up\n",
    "        self.kDataFrame_standardized[high] = self.kDataFrame_standardized[new_high]\n",
    "        self.kDataFrame_standardized[low] = self.kDataFrame_standardized[new_low]\n",
    "        self.kDataFrame_standardized=self.kDataFrame_standardized[['date', 'close', 'high', 'low', 'real_loc']]\n",
    "\n",
    "        # remove standardized kbars\n",
    "        self.kDataFrame_standardized = self.kDataFrame_standardized[self.kDataFrame_standardized['high']!=0]\n",
    "\n",
    "        # new index add for later distance calculation => straight after standardization\n",
    "        self.kDataFrame_standardized = append_fields(self.kDataFrame_standardized, \n",
    "                                                     'new_index',\n",
    "                                                     [i for i in range(len(self.kDataFrame_standardized))],\n",
    "                                                     usemask=False)\n",
    "        return self.kDataFrame_standardized\n",
    "    \n",
    "    def checkTopBot(self, current, first, second):\n",
    "        if float_more(first['high'], current['high']) and float_more(first['high'], second['high']):\n",
    "            return TopBotType.top\n",
    "        elif float_less(first['low'], current['low']) and float_less(first['low'], second['low']):\n",
    "            return TopBotType.bot\n",
    "        else:\n",
    "            return TopBotType.noTopBot\n",
    "    \n",
    "    def markTopBot(self, initial_state=TopBotType.noTopBot):\n",
    "        self.kDataFrame_standardized = append_fields(self.kDataFrame_standardized,\n",
    "                                                     'tb',\n",
    "                                                     [TopBotType.noTopBot.value]*self.kDataFrame_standardized.size,\n",
    "                                                     usemask=False\n",
    "                                                     )\n",
    "        if self.kDataFrame_standardized.size < 7:\n",
    "            return\n",
    "        tb = 'tb'\n",
    "        if initial_state == TopBotType.top or initial_state == TopBotType.bot:\n",
    "            felem = self.kDataFrame_standardized[0]\n",
    "            selem = self.kDataFrame_standardized[1]\n",
    "            if (initial_state == TopBotType.top and float_more_equal(felem['high'], selem['high'])) or \\\n",
    "                (initial_state == TopBotType.bot and float_less_equal(felem['low'], selem['low'])):\n",
    "                self.kDataFrame_standardized[0][tb] = initial_state.value\n",
    "            else:\n",
    "                if self.isdebug:\n",
    "                    print(\"Incorrect initial state given!!!\")\n",
    "                \n",
    "        # This function assume we have done the standardization process (no inclusion)\n",
    "        last_idx = 0\n",
    "        for idx in range(self.kDataFrame_standardized.size-2): #xrange\n",
    "            currentElem = self.kDataFrame_standardized[idx]\n",
    "            firstElem = self.kDataFrame_standardized[idx+1]\n",
    "            secondElem = self.kDataFrame_standardized[idx+2]\n",
    "            topBotType = self.checkTopBot(currentElem, firstElem, secondElem)\n",
    "            if topBotType != TopBotType.noTopBot:\n",
    "                self.kDataFrame_standardized[idx+1][tb] = topBotType.value\n",
    "                last_idx = idx+1\n",
    "                \n",
    "        # mark the first kbar\n",
    "        if (self.kDataFrame_standardized[0][tb] != TopBotType.top.value and\\\n",
    "            self.kDataFrame_standardized[0][tb] != TopBotType.bot.value):\n",
    "            first_loc = get_next_loc(0, self.kDataFrame_standardized)\n",
    "            if first_loc is not None:\n",
    "                first_tb = TopBotType.value2type(self.kDataFrame_standardized[first_loc][tb])\n",
    "                self.kDataFrame_standardized[0][tb] = TopBotType.reverse(first_tb).value\n",
    "            \n",
    "        # mark the last kbar \n",
    "        last_tb = TopBotType.value2type(self.kDataFrame_standardized[last_idx][tb])\n",
    "        self.kDataFrame_standardized[-1][tb] = TopBotType.reverse(last_tb).value\n",
    "        if self.isdebug:\n",
    "            print(\"mark topbot on self.kDataFrame_standardized[20]:{0}\".format(self.kDataFrame_standardized[:20]))\n",
    "            \n",
    "    def trace_back_index(self, working_df, previous_index):\n",
    "        # find the closest FenXing with top/bot backwards from previous_index\n",
    "        idx = previous_index-1\n",
    "        while idx >= 0:\n",
    "            fx = working_df[idx]\n",
    "            if fx['tb'] == TopBotType.noTopBot.value:\n",
    "                idx -= 1\n",
    "                continue\n",
    "            else:\n",
    "                return idx\n",
    "        if self.isdebug:\n",
    "            print(\"We don't have previous valid FenXing\")\n",
    "        return None\n",
    "    \n",
    "    def prepare_original_kdf(self):\n",
    "        if 'macd' not in self.kDataFrame_origin.dtype.names:\n",
    "            _, _, macd = talib.MACD(self.kDataFrame_origin['close'])\n",
    "            macd[np.isnan(macd)] = 0\n",
    "            self.kDataFrame_origin = append_fields(self.kDataFrame_origin,\n",
    "                                                    'macd',\n",
    "                                                    macd,\n",
    "                                                    float,\n",
    "                                                    usemask=False)\n",
    "\n",
    "    def gap_exists_in_range(self, start_idx, end_idx): # end_idx included\n",
    "        # no need to drop first row, simple don't use = \n",
    "        gap_working_df = self.kDataFrame_origin[(start_idx < self.kDataFrame_origin['date']) & (self.kDataFrame_origin['date'] <= end_idx)]\n",
    "        \n",
    "        # drop the first row, as we only need to find gaps from start_idx(non-inclusive) to end_idx(inclusive)  \n",
    "#         gap_working_df = np.delete(gap_working_df, 0, axis=0)\n",
    "        return np.any(gap_working_df['gap']!=0)\n",
    "    \n",
    "    \n",
    "    def gap_exists(self):\n",
    "        high_shift = shift(self.kDataFrame_origin['high'], 1, cval=0)\n",
    "        low_shift = shift(self.kDataFrame_origin['low'], 1, cval=0)\n",
    "        self.kDataFrame_origin = append_fields(self.kDataFrame_origin,\n",
    "                                               ['gap', 'high_shift', 'low_shift', 'gap_range_start', 'gap_range_end'],\n",
    "                                               [\n",
    "                                                   [0]*self.kDataFrame_origin.size,\n",
    "                                                   high_shift,\n",
    "                                                   low_shift,\n",
    "                                                   [0]*self.kDataFrame_origin.size,\n",
    "                                                   [0]*self.kDataFrame_origin.size\n",
    "                                               ],\n",
    "                                               [int, float, float, float, float],\n",
    "                                               usemask=False)\n",
    "        \n",
    "        i = 0\n",
    "        while i < self.kDataFrame_origin.size:\n",
    "            item = self.kDataFrame_origin[i]\n",
    "            if float_more(item['low'] - item['high_shift'], MIN_PRICE_UNIT): # upwards gap\n",
    "                self.kDataFrame_origin[i]['gap'] = 1\n",
    "                self.kDataFrame_origin[i]['gap_range_start'] = item['high_shift']\n",
    "                self.kDataFrame_origin[i]['gap_range_end'] = item['low']\n",
    "            elif float_less(item['high'] - item['low_shift'], -MIN_PRICE_UNIT): # downwards gap\n",
    "                self.kDataFrame_origin[i]['gap'] = -1\n",
    "                self.kDataFrame_origin[i]['gap_range_start'] = item['high']\n",
    "                self.kDataFrame_origin[i]['gap_range_end'] = item['low_shift']\n",
    "            i = i + 1\n",
    "        \n",
    "#         self.kDataFrame_origin = self.kDataFrame_origin[FEN_BI_COLUMNS + ['gap', 'gap_range_start', 'gap_range_end']]\n",
    "#         if self.isdebug:\n",
    "#             print(self.kDataFrame_origin[self.kDataFrame_origin['gap']])\n",
    "    \n",
    "    def gap_region(self, start_idx, end_idx, direction=TopBotType.noTopBot):\n",
    "        # no need to drop first row, simple don't use = \n",
    "        gap_working_df = self.kDataFrame_origin[(start_idx < self.kDataFrame_origin['date']) & (self.kDataFrame_origin['date'] <= end_idx)]\n",
    "        if direction == TopBotType.noTopBot:\n",
    "            return gap_working_df[gap_working_df['gap']!=0][['gap_range_start', 'gap_range_end']].tolist()\n",
    "        elif direction == TopBotType.top2bot:\n",
    "            return gap_working_df[gap_working_df['gap']==-1][['gap_range_start', 'gap_range_end']].tolist()\n",
    "        elif direction == TopBotType.bot2top:\n",
    "            return gap_working_df[gap_working_df['gap']==1][['gap_range_start', 'gap_range_end']].tolist()\n",
    "\n",
    "    def get_next_tb(self, idx, working_df):\n",
    "        '''\n",
    "        give the next loc from current idx(excluded) if overflow return size of working_df\n",
    "        '''\n",
    "        i = idx+1\n",
    "        while i < working_df.size:\n",
    "            if working_df[i]['tb'] == TopBotType.top.value or working_df[i]['tb'] == TopBotType.bot.value:\n",
    "                break\n",
    "            i += 1\n",
    "        return i\n",
    "\n",
    "    def clean_first_two_tb(self, working_df):\n",
    "        ############################# make sure the first two Ding/Di are valid to start with ###########################\n",
    "        firstIdx = 0\n",
    "        secondIdx= firstIdx+1\n",
    "        thirdIdx = secondIdx+1\n",
    "        tb = 'tb'\n",
    "        high = 'high'\n",
    "        low = 'low'\n",
    "        new_index = 'new_index'\n",
    "\n",
    "        while thirdIdx is not None and thirdIdx < working_df.size:\n",
    "            firstFenXing = working_df[firstIdx]\n",
    "            secondFenXing = working_df[secondIdx]\n",
    "            thirdFenXing = working_df[thirdIdx]\n",
    "            if firstFenXing[tb] == secondFenXing[tb] == TopBotType.top.value and float_less(firstFenXing[high], secondFenXing[high]):\n",
    "                working_df[firstIdx][tb] = TopBotType.noTopBot.value\n",
    "                firstIdx = get_next_loc(firstIdx, working_df)\n",
    "                secondIdx=get_next_loc(firstIdx, working_df)\n",
    "                thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                continue\n",
    "            elif firstFenXing[tb] == secondFenXing[tb] == TopBotType.top.value and float_more_equal(firstFenXing[high], secondFenXing[high]):\n",
    "                working_df[secondIdx][tb] = TopBotType.noTopBot.value\n",
    "                secondIdx = get_next_loc(secondIdx, working_df)\n",
    "                thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                continue\n",
    "            elif firstFenXing[tb] == secondFenXing[tb] == TopBotType.bot.value and float_more(firstFenXing[low], secondFenXing[low]):\n",
    "                working_df[firstIdx][tb] = TopBotType.noTopBot.value\n",
    "                firstIdx = get_next_loc(firstIdx, working_df)\n",
    "                secondIdx=get_next_loc(firstIdx, working_df)\n",
    "                thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                continue\n",
    "            elif firstFenXing[tb] == secondFenXing[tb] == TopBotType.bot.value and float_less_equal(firstFenXing[low], secondFenXing[low]):\n",
    "                working_df[secondIdx][tb] = TopBotType.noTopBot.value\n",
    "                secondIdx = get_next_loc(secondIdx, working_df)\n",
    "                thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                continue\n",
    "            elif secondFenXing[new_index] - firstFenXing[new_index] < 4:\n",
    "                if firstFenXing[tb] == thirdFenXing[tb] == TopBotType.top.value and float_less(firstFenXing[high], thirdFenXing[high]):\n",
    "                    working_df[firstIdx][tb] = TopBotType.noTopBot.value\n",
    "                    firstIdx = get_next_loc(firstIdx, working_df)\n",
    "                    secondIdx=get_next_loc(firstIdx, working_df)\n",
    "                    thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                    continue\n",
    "                elif firstFenXing[tb] == thirdFenXing[tb] == TopBotType.top.value and float_more_equal(firstFenXing[high], thirdFenXing[high]):\n",
    "                    working_df[secondIdx][tb] = TopBotType.noTopBot.value\n",
    "                    secondIdx=get_next_loc(secondIdx, working_df)\n",
    "                    thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                    continue\n",
    "                elif firstFenXing[tb] == thirdFenXing[tb] == TopBotType.bot.value and float_more(firstFenXing[low], thirdFenXing[low]):\n",
    "                    working_df[firstIdx][tb] = TopBotType.noTopBot.value\n",
    "                    firstIdx = get_next_loc(firstIdx, working_df)\n",
    "                    secondIdx=get_next_loc(firstIdx, working_df)\n",
    "                    thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                    continue\n",
    "                elif firstFenXing[tb] == thirdFenXing[tb] == TopBotType.bot.value and float_less_equal(firstFenXing[low], thirdFenXing[low]):\n",
    "                    working_df[secondIdx][tb] = TopBotType.noTopBot.value\n",
    "                    secondIdx=get_next_loc(secondIdx, working_df)\n",
    "                    thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"somthing WRONG!\")\n",
    "                    return\n",
    "                    \n",
    "            elif firstFenXing[tb] == TopBotType.top.value and secondFenXing[tb] == TopBotType.bot.value and float_less_equal(firstFenXing[high], secondFenXing[low]):\n",
    "                working_df[firstIdx][tb] = TopBotType.noTopBot.value\n",
    "                working_df[secondIdx][tb] = TopBotType.noTopBot.value\n",
    "                firstIdx = get_next_loc(firstIdx, working_df)\n",
    "                secondIdx=get_next_loc(firstIdx, working_df)\n",
    "                thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                continue\n",
    "            elif firstFenXing[tb] == TopBotType.bot.value and secondFenXing[tb] == TopBotType.top.value and float_more_equal(firstFenXing[low], secondFenXing[high]):\n",
    "                working_df[firstIdx][tb] = TopBotType.noTopBot.value\n",
    "                working_df[secondIdx][tb] = TopBotType.noTopBot.value\n",
    "                firstIdx = get_next_loc(firstIdx, working_df)\n",
    "                secondIdx=get_next_loc(firstIdx, working_df)\n",
    "                thirdIdx=get_next_loc(secondIdx, working_df)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    " \n",
    "        working_df = working_df[working_df[tb]!=TopBotType.noTopBot.value]\n",
    "        return working_df\n",
    "        \n",
    "    def check_gap_qualify(self, working_df, previous_index, current_index, next_index):\n",
    "        # possible BI status 1 check top high > bot low 2 check more than 3 bars (strict BI) in between\n",
    "        # under this section of code we expect there are no two adjacent fenxings with the same status\n",
    "        gap_qualify = False\n",
    "        if self.gap_exists_in_range(working_df[current_index]['date'], working_df[next_index]['date']):\n",
    "            gap_direction = TopBotType.bot2top if working_df[next_index]['tb'] == TopBotType.top.value else\\\n",
    "                            TopBotType.top2bot if working_df[next_index]['tb'] == TopBotType.bot.value else\\\n",
    "                            TopBotType.noTopBot\n",
    "            gap_ranges = self.gap_region(working_df[current_index]['date'], working_df[next_index]['date'], gap_direction)\n",
    "            gap_ranges = self.combine_gaps(gap_ranges)\n",
    "            for gap in gap_ranges:\n",
    "                if previous_index is None:\n",
    "                    return True\n",
    "                    \n",
    "                if working_df[previous_index]['tb'] == TopBotType.top.value: \n",
    "                    #gap higher than previous high\n",
    "                    gap_qualify = float_less(gap[0], working_df[previous_index]['low']) and\\\n",
    "                                  float_less_equal(working_df[previous_index]['low'], working_df[previous_index]['high']) and\\\n",
    "                                  float_less(working_df[previous_index]['high'], gap[1])\n",
    "                elif working_df[previous_index]['tb'] == TopBotType.bot.value:\n",
    "                    #gap higher than previous low\n",
    "                    gap_qualify = float_more(gap[1], working_df[previous_index]['high']) and\\\n",
    "                                  float_more_equal(working_df[previous_index]['high'], working_df[previous_index]['low']) and\\\n",
    "                                  float_more(working_df[previous_index]['low'], gap[0])\n",
    "                if gap_qualify:\n",
    "                    break\n",
    "        return gap_qualify\n",
    "        \n",
    "    def same_tb_remove_previous(self, working_df, previous_index, current_index, next_index):\n",
    "        working_df[previous_index]['tb'] = TopBotType.noTopBot.value\n",
    "        previous_index = self.trace_back_index(working_df, previous_index) #current_index # \n",
    "        if previous_index is None:\n",
    "            previous_index = current_index\n",
    "            current_index = next_index\n",
    "            next_index = self.get_next_tb(next_index, working_df)\n",
    "        else:\n",
    "            if previous_index in self.previous_skipped_idx:\n",
    "                self.previous_skipped_idx.remove(previous_index)\n",
    "            \n",
    "        return previous_index, current_index, next_index\n",
    "\n",
    "    def same_tb_remove_current(self, working_df, previous_index, current_index, next_index):\n",
    "        working_df[current_index]['tb'] = TopBotType.noTopBot.value\n",
    "        temp_index = previous_index\n",
    "        current_index = previous_index\n",
    "        previous_index = self.trace_back_index(working_df, previous_index)\n",
    "        if previous_index is None:\n",
    "            previous_index = temp_index\n",
    "            current_index = next_index\n",
    "            next_index = self.get_next_tb(next_index, working_df)\n",
    "        else:\n",
    "            if previous_index in self.previous_skipped_idx:\n",
    "                self.previous_skipped_idx.remove(previous_index)\n",
    "        \n",
    "        return previous_index, current_index, next_index\n",
    "    \n",
    "    def same_tb_remove_next(self, working_df, previous_index, current_index, next_index):\n",
    "        working_df[next_index]['tb'] = TopBotType.noTopBot.value\n",
    "        temp_index = previous_index\n",
    "        previous_index = self.trace_back_index(working_df, previous_index)\n",
    "        if previous_index is None:\n",
    "            previous_index = temp_index\n",
    "            next_index = self.get_next_tb(next_index, working_df)\n",
    "        else:\n",
    "            next_index = current_index\n",
    "            current_index = temp_index\n",
    "            if previous_index in self.previous_skipped_idx:\n",
    "                self.previous_skipped_idx.remove(previous_index)\n",
    "            \n",
    "        return previous_index, current_index, next_index\n",
    "    \n",
    "\n",
    "    def defineBi(self):\n",
    "        '''\n",
    "        This method defines fenbi for all marked top/bot:\n",
    "        three indices maintained. \n",
    "        if the first two have < 4 new_index distance, we move forward\n",
    "        if the second two have < 4 new_index distance, we move forward, but mark the first index\n",
    "        if the second two have >= 4 new_index distance, we make decision on which one to remove, and go backwards\n",
    "        if we hit all good three kbars, we check marked record and start from there\n",
    "        finally, if we hit end but still have marked index, we make decision to remove one kbar and resume till finishes\n",
    "        '''\n",
    "        \n",
    "        self.gap_exists() # work out gap in the original kline\n",
    "        working_df = self.kDataFrame_standardized[self.kDataFrame_standardized['tb']!=TopBotType.noTopBot.value]\n",
    "        tb = 'tb'\n",
    "        high = 'high'\n",
    "        low = 'low'\n",
    "        new_index = 'new_index'\n",
    "        \n",
    "        working_df = self.clean_first_two_tb(working_df)\n",
    "        \n",
    "        #################################\n",
    "        previous_index = 0\n",
    "        current_index = previous_index + 1\n",
    "        next_index = current_index + 1\n",
    "        #################################\n",
    "        while next_index < working_df.size and previous_index is not None and next_index is not None:\n",
    "            previousFenXing = working_df[previous_index]\n",
    "            currentFenXing = working_df[current_index]\n",
    "            nextFenXing = working_df[next_index]\n",
    "            \n",
    "            if currentFenXing[tb] == previousFenXing[tb]: # used to track back the skipped previous_index\n",
    "                if currentFenXing[tb] == TopBotType.top.value:\n",
    "                    if float_less(currentFenXing[high], previousFenXing[high]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                    elif float_more(currentFenXing[high], previousFenXing[high]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_previous(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                    else: # equal case\n",
    "                        gap_qualify = self.check_gap_qualify(working_df, previous_index, current_index, next_index)\n",
    "                        # only remove current if it's not valid with next in case of equality\n",
    "                        if working_df[next_index][new_index] - working_df[current_index][new_index] < 4 and not gap_qualify:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                        else:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_previous(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                    continue\n",
    "                elif currentFenXing[tb] == TopBotType.bot.value:\n",
    "                    if float_more(currentFenXing[low], previousFenXing[low]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                    elif float_less(currentFenXing[low], previousFenXing[low]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_previous(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                    else:# equal case\n",
    "                        gap_qualify = self.check_gap_qualify(working_df, previous_index, current_index, next_index)\n",
    "                        # only remove current if it's not valid with next in case of equality\n",
    "                        if working_df[next_index][new_index] - working_df[current_index][new_index] < 4 and not gap_qualify:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                        else:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_previous(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                    continue\n",
    "            elif currentFenXing[tb] == nextFenXing[tb]:\n",
    "                if currentFenXing[tb] == TopBotType.top.value:\n",
    "                    if float_less(currentFenXing[high], nextFenXing[high]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                        \n",
    "                    elif float_more(currentFenXing[high], nextFenXing[high]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_next(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                    else: #equality case\n",
    "                        pre_pre_index = self.trace_back_index(working_df, previous_index)\n",
    "                        if pre_pre_index is None:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                            continue\n",
    "                        gap_qualify = self.check_gap_qualify(working_df, pre_pre_index, previous_index, current_index)\n",
    "                        if working_df[current_index][new_index] - working_df[previous_index][new_index] >= 4 or gap_qualify:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_next(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                        else:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                    continue\n",
    "                elif currentFenXing[tb] == TopBotType.bot.value:\n",
    "                    if float_more(currentFenXing[low], nextFenXing[low]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                    elif float_less(currentFenXing[low], nextFenXing[low]):\n",
    "                        previous_index, current_index, next_index = self.same_tb_remove_next(working_df, \n",
    "                                                                                                 previous_index, \n",
    "                                                                                                 current_index, \n",
    "                                                                                                 next_index)\n",
    "                    else:\n",
    "                        pre_pre_index = self.trace_back_index(working_df, previous_index)\n",
    "                        if pre_pre_index is None:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                            continue\n",
    "                        gap_qualify = self.check_gap_qualify(working_df, pre_pre_index, previous_index, current_index)\n",
    "                        if working_df[current_index][new_index] - working_df[previous_index][new_index] >= 4 or gap_qualify:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_next(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                        else:\n",
    "                            previous_index, current_index, next_index = self.same_tb_remove_current(working_df, \n",
    "                                                                                                     previous_index, \n",
    "                                                                                                     current_index, \n",
    "                                                                                                     next_index)\n",
    "                    continue\n",
    "            \n",
    "            gap_qualify = self.check_gap_qualify(working_df, previous_index, current_index, next_index)\n",
    "            if currentFenXing[new_index] - previousFenXing[new_index] < 4:\n",
    "                # comming from current next less than 4 new_index gap, we need to determine which ones to kill\n",
    "                # once done we trace back\n",
    "                if (nextFenXing[new_index] - currentFenXing[new_index]) >= 4 or gap_qualify:\n",
    "                    pre_pre_index = self.trace_back_index(working_df, previous_index)\n",
    "                    \n",
    "                    # if previous current are good, we go next\n",
    "                    if self.check_gap_qualify(working_df, pre_pre_index, previous_index, current_index):\n",
    "                        pass\n",
    "                    \n",
    "                    elif currentFenXing[tb] == TopBotType.bot.value and\\\n",
    "                        previousFenXing[tb] == TopBotType.top.value and\\\n",
    "                        nextFenXing[tb] == TopBotType.top.value:\n",
    "                        if float_more_equal(previousFenXing[high], nextFenXing[high]):\n",
    "                            # still can't make decision, but we can have idea about prepre case\n",
    "                            pre_pre_index = self.trace_back_index(working_df, previous_index)\n",
    "                            if pre_pre_index is None:\n",
    "                                working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                                current_index = next_index\n",
    "                                next_index = self.get_next_tb(next_index, working_df)\n",
    "                                continue\n",
    "                            \n",
    "                            if pre_pre_index in self.previous_skipped_idx:\n",
    "                                self.previous_skipped_idx.remove(pre_pre_index)\n",
    "                            prepreFenXing = working_df[pre_pre_index]\n",
    "                            if float_more_equal(prepreFenXing[low], currentFenXing[low]):\n",
    "                                working_df[pre_pre_index][tb] = TopBotType.noTopBot.value\n",
    "                                temp_index = self.trace_back_index(working_df, pre_pre_index)\n",
    "                                if temp_index is None:\n",
    "                                    working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                                    current_index = next_index\n",
    "                                    next_index = self.get_next_tb(next_index, working_df)\n",
    "                                else:\n",
    "                                    next_index = current_index\n",
    "                                    current_index = previous_index\n",
    "                                    previous_index = temp_index\n",
    "                                    if previous_index in self.previous_skipped_idx:\n",
    "                                        self.previous_skipped_idx.remove(previous_index)\n",
    "                                continue\n",
    "                            else:\n",
    "                                working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                                current_index = previous_index\n",
    "                                previous_index = self.trace_back_index(working_df, previous_index)\n",
    "                                if previous_index in self.previous_skipped_idx:\n",
    "                                    self.previous_skipped_idx.remove(previous_index)\n",
    "                                continue\n",
    "                        else: #previousFenXing[high] < nextFenXing[high]\n",
    "                            working_df[previous_index][tb] = TopBotType.noTopBot.value\n",
    "                            previous_index = self.trace_back_index(working_df, previous_index)\n",
    "                            if previous_index in self.previous_skipped_idx:\n",
    "                                self.previous_skipped_idx.remove(previous_index)\n",
    "                            continue\n",
    "                            \n",
    "                    elif currentFenXing[tb] == TopBotType.top.value and\\\n",
    "                        previousFenXing[tb] == TopBotType.bot.value and\\\n",
    "                        nextFenXing[tb] == TopBotType.bot.value:\n",
    "                        if float_less(previousFenXing[low], nextFenXing[low]):\n",
    "                            # still can't make decision, but we can have idea about prepre case\n",
    "                            pre_pre_index = self.trace_back_index(working_df, previous_index)\n",
    "                            if pre_pre_index is None:\n",
    "                                working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                                current_index = next_index\n",
    "                                next_index = self.get_next_tb(next_index, working_df)\n",
    "                                continue\n",
    "                            \n",
    "                            if pre_pre_index in self.previous_skipped_idx:\n",
    "                                self.previous_skipped_idx.remove(pre_pre_index)\n",
    "                            prepreFenXing = working_df[pre_pre_index]\n",
    "                            if float_less_equal(prepreFenXing[high], currentFenXing[high]):\n",
    "                                working_df[pre_pre_index][tb] = TopBotType.noTopBot.value\n",
    "                                temp_index = self.trace_back_index(working_df, pre_pre_index)\n",
    "                                if temp_index is None:\n",
    "                                    working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                                    current_index = next_index\n",
    "                                    next_index = self.get_next_tb(next_index, working_df)\n",
    "                                else:\n",
    "                                    next_index = current_index\n",
    "                                    current_index = previous_index\n",
    "                                    previous_index = temp_index\n",
    "                                    if previous_index in self.previous_skipped_idx:\n",
    "                                        self.previous_skipped_idx.remove(previous_index)\n",
    "                                continue\n",
    "                            else:\n",
    "                                working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                                current_index = previous_index\n",
    "                                previous_index = self.trace_back_index(working_df, previous_index)\n",
    "                                if previous_index in self.previous_skipped_idx:\n",
    "                                    self.previous_skipped_idx.remove(previous_index)\n",
    "                                continue\n",
    "                        else: #previousFenXing[low] >= nextFenXing[low]\n",
    "                            working_df[previous_index][tb] = TopBotType.noTopBot.value\n",
    "                            previous_index = self.trace_back_index(working_df, previous_index)\n",
    "                            if previous_index in self.previous_skipped_idx:\n",
    "                                self.previous_skipped_idx.remove(previous_index)\n",
    "                            continue\n",
    "                else: #(nextFenXing[new_index] - currentFenXing[new_index]) < 4 and not gap_qualify:\n",
    "                    temp_index = self.get_next_tb(next_index, working_df)\n",
    "                    if temp_index == working_df.size: # we reached the end, need to go back\n",
    "                        previous_index, current_index, next_index = self.work_on_end(previous_index, \n",
    "                                                                                     current_index, \n",
    "                                                                                     next_index, \n",
    "                                                                                     working_df)\n",
    "                    else:\n",
    "                        # leave it for next round again!\n",
    "                        self.previous_skipped_idx.append(previous_index) # mark index so we come back \n",
    "                        previous_index = current_index\n",
    "                        current_index = next_index\n",
    "                        next_index = temp_index\n",
    "                    continue\n",
    "                \n",
    "            elif (nextFenXing[new_index] - currentFenXing[new_index]) < 4 and not gap_qualify: \n",
    "                temp_index = self.get_next_tb(next_index, working_df)\n",
    "                if temp_index == working_df.size: # we reached the end, need to go back\n",
    "                    previous_index, current_index, next_index = self.work_on_end(previous_index, \n",
    "                                                                                 current_index, \n",
    "                                                                                 next_index, \n",
    "                                                                                 working_df)\n",
    "                else:\n",
    "                    # leave it for next round again!\n",
    "                    self.previous_skipped_idx.append(previous_index) # mark index so we come back \n",
    "                    previous_index = current_index\n",
    "                    current_index = next_index\n",
    "                    next_index = temp_index\n",
    "                continue\n",
    "            elif (nextFenXing[new_index] - currentFenXing[new_index]) >= 4 or gap_qualify:\n",
    "                if currentFenXing[tb] == TopBotType.top.value and nextFenXing[tb] == TopBotType.bot.value and float_more(currentFenXing[high], nextFenXing[high]):\n",
    "                    pass\n",
    "                elif currentFenXing[tb] == TopBotType.top.value and nextFenXing[tb] == TopBotType.bot.value and float_less_equal(currentFenXing[high], nextFenXing[high]):\n",
    "                    working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                    current_index = next_index\n",
    "                    next_index = self.get_next_tb(next_index, working_df)\n",
    "                    continue\n",
    "                \n",
    "                elif currentFenXing[tb] == TopBotType.top.value and nextFenXing[tb] == TopBotType.bot.value and float_less_equal(currentFenXing[low],nextFenXing[low]):\n",
    "                    working_df[next_index][tb] = TopBotType.noTopBot.value\n",
    "                    next_index = self.get_next_tb(next_index, working_df)\n",
    "                    continue\n",
    "                elif currentFenXing[tb] == TopBotType.top.value and nextFenXing[tb] == TopBotType.bot.value and float_more(currentFenXing[low], nextFenXing[low]):\n",
    "                    pass\n",
    "                \n",
    "                elif currentFenXing[tb] == TopBotType.bot.value and nextFenXing[tb] == TopBotType.top.value and float_less(currentFenXing[low], nextFenXing[low]):\n",
    "                    pass\n",
    "                elif currentFenXing[tb] == TopBotType.bot.value and nextFenXing[tb] == TopBotType.top.value and float_more_equal(currentFenXing[low], nextFenXing[low]):\n",
    "                    working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                    current_index = next_index \n",
    "                    next_index = self.get_next_tb(next_index, working_df)\n",
    "                    continue\n",
    "                elif currentFenXing[tb] == TopBotType.bot.value and nextFenXing[tb] == TopBotType.top.value and float_less(currentFenXing[high], nextFenXing[high]):\n",
    "                    pass\n",
    "                elif currentFenXing[tb] == TopBotType.bot.value and nextFenXing[tb] == TopBotType.top.value and float_more_equal(currentFenXing[high], nextFenXing[high]):\n",
    "                    working_df[next_index][tb] = TopBotType.noTopBot.value\n",
    "                    next_index = self.get_next_tb(next_index, working_df)\n",
    "                    continue\n",
    "            \n",
    "            if self.previous_skipped_idx: # if we still have some left to do\n",
    "                previous_index = self.previous_skipped_idx.pop()\n",
    "                if working_df[previous_index][tb] == TopBotType.noTopBot.value:\n",
    "                    previous_index = self.get_next_tb(previous_index, working_df)\n",
    "                current_index = self.get_next_tb(previous_index, working_df)\n",
    "                next_index = self.get_next_tb(current_index, working_df)\n",
    "                continue\n",
    "            \n",
    "            # only confirmed tb comes here\n",
    "            previous_index = current_index\n",
    "            current_index=next_index\n",
    "            next_index = self.get_next_tb(next_index, working_df)\n",
    "\n",
    "        # if nextIndex is the last one, final clean up\n",
    "        if next_index == working_df.size:\n",
    "            if ((working_df[current_index][tb]==TopBotType.top.value and float_more(self.kDataFrame_origin[-1][high], working_df[current_index][high])) \\\n",
    "                or (working_df[current_index][tb]==TopBotType.bot.value and float_less(self.kDataFrame_origin[-1][low], working_df[current_index][low]) )):\n",
    "                working_df[-1][tb] = working_df[current_index][tb]\n",
    "                working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "            \n",
    "            if working_df[current_index][tb] == TopBotType.noTopBot.value and\\\n",
    "                ((working_df[previous_index][tb]==TopBotType.top.value and float_more(self.kDataFrame_origin[-1][high], working_df[previous_index][high])) or\\\n",
    "                 (working_df[previous_index][tb]==TopBotType.bot.value and float_less(self.kDataFrame_origin[-1][low], working_df[previous_index][low]))):\n",
    "                working_df[-1][tb] = working_df[previous_index][tb]\n",
    "                working_df[previous_index][tb] = TopBotType.noTopBot.value\n",
    "                \n",
    "            if working_df[previous_index][tb] == working_df[current_index][tb]:\n",
    "                if working_df[current_index][tb] == TopBotType.top.value:\n",
    "                    if float_more(working_df[current_index][high],working_df[previous_index][high]):\n",
    "                        working_df[previous_index][tb] = TopBotType.noTopBot.value\n",
    "                    else:\n",
    "                        working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "                elif working_df[current_index][tb] == TopBotType.bot.value:\n",
    "                    if float_less(working_df[current_index][low], working_df[previous_index][low]):\n",
    "                        working_df[previous_index][tb] = TopBotType.noTopBot.value\n",
    "                    else:\n",
    "                        working_df[current_index][tb] = TopBotType.noTopBot.value\n",
    "        ###################################    \n",
    "        self.kDataFrame_marked = working_df[working_df[tb]!=TopBotType.noTopBot.value][FEN_BI_COLUMNS]\n",
    "        if self.isdebug:\n",
    "            print(\"self.kDataFrame_marked head 20:{0}\".format(self.kDataFrame_marked[:20]))\n",
    "            print(\"self.kDataFrame_marked tail 20:{0}\".format(self.kDataFrame_marked[-20:]))\n",
    "\n",
    "\n",
    "    def work_on_end(self, pre_idx, cur_idx, nex_idx, working_df):\n",
    "        '''\n",
    "        only triggered at the end of fenbi loop\n",
    "        '''\n",
    "        previousFenXing = working_df[pre_idx]\n",
    "        currentFenXing = working_df[cur_idx]\n",
    "        nextFenXing = working_df[nex_idx]\n",
    "\n",
    "        if currentFenXing['tb'] == TopBotType.top.value:\n",
    "            if float_more(previousFenXing['low'], nextFenXing['low']):\n",
    "                working_df[pre_idx]['tb'] = TopBotType.noTopBot.value\n",
    "                pre_idx = self.trace_back_index(working_df, pre_idx)\n",
    "            else:\n",
    "                working_df[nex_idx]['tb'] = TopBotType.noTopBot.value\n",
    "                nex_idx = cur_idx\n",
    "                cur_idx = pre_idx\n",
    "                pre_idx = self.trace_back_index(working_df, pre_idx)\n",
    "        else: # TopBotType.bot\n",
    "            if float_less(previousFenXing['high'], nextFenXing['high']):\n",
    "                working_df[pre_idx]['tb'] = TopBotType.noTopBot.value\n",
    "                pre_idx = self.trace_back_index(working_df, pre_idx)\n",
    "            else:\n",
    "                working_df[nex_idx]['tb'] = TopBotType.noTopBot.value\n",
    "                nex_idx = cur_idx\n",
    "                cur_idx = pre_idx\n",
    "                pre_idx = self.trace_back_index(working_df, pre_idx)\n",
    "        if pre_idx in self.previous_skipped_idx:\n",
    "            self.previous_skipped_idx.remove(pre_idx)\n",
    "        return pre_idx, cur_idx, nex_idx\n",
    "\n",
    "    def getMarkedBL(self):\n",
    "        self.standardize()\n",
    "        self.markTopBot()\n",
    "        self.defineBi()\n",
    "#         self.defineBi_new()\n",
    "        self.getPureBi()\n",
    "        return self.kDataFrame_marked\n",
    "    \n",
    "    def getPureBi(self):\n",
    "        # only use the price relavent\n",
    "        self.kDataFrame_marked = append_fields(self.kDataFrame_marked,\n",
    "                                               'chan_price',\n",
    "                                               [0]*len(self.kDataFrame_marked),\n",
    "                                               float,\n",
    "                                               usemask=False)\n",
    "        i = 0\n",
    "        while i < self.kDataFrame_marked.size:\n",
    "            item = self.kDataFrame_marked[i]\n",
    "            if item['tb'] == TopBotType.top.value:\n",
    "                self.kDataFrame_marked[i]['chan_price'] = item['high']\n",
    "            elif item['tb'] == TopBotType.bot.value:\n",
    "                self.kDataFrame_marked[i]['chan_price'] = item['low']\n",
    "            else:\n",
    "                print(\"Invalid tb for chan_price\")\n",
    "            i = i + 1\n",
    "            \n",
    "        if self.isdebug:\n",
    "            print(\"getPureBi:{0}\".format(self.kDataFrame_marked[['date', 'chan_price', 'tb', 'real_loc']][-20:]))\n",
    "\n",
    "    def getFenBi(self, initial_state=TopBotType.noTopBot):\n",
    "        self.standardize(initial_state)\n",
    "        self.markTopBot(initial_state)\n",
    "        self.defineBi()\n",
    "        self.getPureBi()\n",
    "        return self.kDataFrame_marked\n",
    "\n",
    "    def getFenDuan(self, initial_state=TopBotType.noTopBot):\n",
    "        temp_df = self.getFenBi(initial_state)\n",
    "        if temp_df.size==0:\n",
    "            return temp_df\n",
    "        self.defineXD(initial_state)\n",
    "        return self.kDataFrame_xd\n",
    "    \n",
    "    def getOriginal_df(self):\n",
    "        return self.kDataFrame_origin\n",
    "    \n",
    "    def getFenBI_df(self):\n",
    "        return self.kDataFrame_marked\n",
    "    \n",
    "    def getFenDuan_df(self):\n",
    "        return self.kDataFrame_xd\n",
    "\n",
    "\n",
    "################################################## XD defintion ##################################################      \n",
    "\n",
    "    def find_initial_direction(self, working_df, initial_status=TopBotType.noTopBot):\n",
    "        chan_price = 'chan_price'\n",
    "        if initial_status != TopBotType.noTopBot:\n",
    "            # first six elem, this can only be used when we are sure about the direction of the xd\n",
    "            if initial_status == TopBotType.top:\n",
    "                initial_loc = working_df[:6]['chan_price'].argmax(axis=0)\n",
    "            elif initial_status == TopBotType.bot:\n",
    "                initial_loc = working_df[:6]['chan_price'].argmin(axis=0)\n",
    "            else:\n",
    "                initial_loc = None\n",
    "                print(\"Invalid Initial TopBot type\")\n",
    "            working_df[initial_loc]['xd_tb'] = initial_status.value\n",
    "            if self.isdebug:\n",
    "                print(\"initial xd_tb:{0} located at {1}\".format(initial_status, working_df[initial_loc]['date']))\n",
    "            initial_direction = TopBotType.top2bot if initial_status == TopBotType.top else TopBotType.bot2top\n",
    "        else:\n",
    "            initial_loc = current_loc = 0\n",
    "            initial_direction = TopBotType.noTopBot\n",
    "            while current_loc + 3 < working_df.size:\n",
    "                first = working_df[current_loc]\n",
    "                second = working_df[current_loc+1]\n",
    "                third = working_df[current_loc+2]\n",
    "                forth = working_df[current_loc+3]\n",
    "                \n",
    "                if float_less(first[chan_price], second[chan_price]):\n",
    "                    found_direction = (float_less_equal(first[chan_price],third[chan_price]) and float_less(second[chan_price],forth[chan_price])) or\\\n",
    "                                        (float_more_equal(first[chan_price],third[chan_price]) and float_more(second[chan_price],forth[chan_price]))\n",
    "                else:\n",
    "                    found_direction = (float_less(first[chan_price],third[chan_price]) and float_less_equal(second[chan_price],forth[chan_price])) or\\\n",
    "                                        (float_more(first[chan_price],third[chan_price]) and float_more_equal(second[chan_price],forth[chan_price]))\n",
    "                                    \n",
    "                if found_direction:\n",
    "                    initial_direction = TopBotType.bot2top if (float_less(first[chan_price],third[chan_price]) or float_less(second[chan_price],forth[chan_price])) else TopBotType.top2bot\n",
    "                    initial_loc = current_loc\n",
    "                    break\n",
    "                else:\n",
    "                    current_loc = current_loc + 1\n",
    "            \n",
    "        return initial_loc, initial_direction\n",
    "\n",
    "    def combine_gaps(self, gap_regions):\n",
    "        '''\n",
    "        gap regions come in as ordered\n",
    "        '''\n",
    "        i = 0 \n",
    "        if len(gap_regions) <= 1:\n",
    "            return gap_regions\n",
    "        \n",
    "        # sort gap regions\n",
    "        gap_regions = sorted(gap_regions, key=lambda tup: tup[0])\n",
    "        \n",
    "        new_gaps = []\n",
    "        temp_range= None\n",
    "        while i + 1 < len(gap_regions):\n",
    "            current_range = gap_regions[i]\n",
    "            next_range = gap_regions[i+1]\n",
    "            \n",
    "            if temp_range is None:\n",
    "                if float_more_equal(current_range[1], next_range[0]):\n",
    "                    temp_range = (current_range[0], next_range[1])\n",
    "                else:\n",
    "                    new_gaps.append(current_range)\n",
    "                    temp_range = next_range\n",
    "            else:\n",
    "                if float_more_equal(temp_range[1], next_range[0]):\n",
    "                    temp_range = (temp_range[0], next_range[1])\n",
    "                else:\n",
    "                    new_gaps.append(temp_range)\n",
    "                    temp_range = next_range\n",
    "            i = i + 1\n",
    "        new_gaps.append(temp_range)\n",
    "                \n",
    "        return new_gaps\n",
    "\n",
    "    def kbar_gap_as_xd(self, working_df, first_idx, second_idx, compare_idx):\n",
    "        '''\n",
    "        check given gapped kbar can be considered xd alone\n",
    "        '''\n",
    "        firstElem = working_df[first_idx]\n",
    "        secondElem = working_df[second_idx]\n",
    "        compareElem = working_df[compare_idx] if compare_idx is not None else None\n",
    "        item_price_covered = False\n",
    "        gap_range_in_portion = False\n",
    "        if first_idx + 1 == second_idx and\\\n",
    "            self.gap_exists_in_range(firstElem['date'], secondElem['date']):\n",
    "            gap_direction = TopBotType.bot2top if secondElem['tb'] == TopBotType.top.value else\\\n",
    "                            TopBotType.top2bot if secondElem['tb'] == TopBotType.bot.value else\\\n",
    "                            TopBotType.noTopBot\n",
    "            regions = self.gap_region(firstElem['date'], secondElem['date'], gap_direction)\n",
    "            if regions:\n",
    "                regions = self.combine_gaps(regions)\n",
    "    #             for re in regions:\n",
    "    # #                 if float_less_equal(re[0], compareElem['chan_price']) and float_less_equal(compareElem['chan_price'], re[1]):\n",
    "    # #                     item_price_covered = True\n",
    "    #                 if float_more_equal((re[1]-re[0])/abs(firstElem['chan_price']-secondElem['chan_price']), GOLDEN_RATIO):\n",
    "    #                     gap_range_in_portion = True\n",
    "    #                 if gap_range_in_portion:\n",
    "    #                     return gap_range_in_portion\n",
    "                    \n",
    "                gap_range = sum([(b-a) for a, b in regions])\n",
    "                if float_more_equal(gap_range/abs(firstElem['chan_price']-secondElem['chan_price']), 1-GOLDEN_RATIO):\n",
    "                    gap_range_in_portion = True\n",
    "                \n",
    "                if compareElem is None:\n",
    "                    item_price_covered = True\n",
    "                else:\n",
    "                    if gap_direction == TopBotType.top2bot:\n",
    "                        item_price_covered = float_less_equal(regions[0][0], compareElem['chan_price'])\n",
    "                    elif gap_direction == TopBotType.bot2top:\n",
    "                        item_price_covered = float_more_equal(regions[-1][1], compareElem['chan_price'])\n",
    "                    else:\n",
    "                        item_price_covered = False\n",
    "                \n",
    "                if gap_range_in_portion and item_price_covered:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "    def xd_inclusion(self, firstElem, secondElem, thirdElem, forthElem):\n",
    "        '''\n",
    "        given four elem check the xd formed contain inclusive relationship, positive as True, negative as False\n",
    "        '''\n",
    "        if (float_less_equal(firstElem['chan_price'], thirdElem['chan_price']) and float_more_equal(secondElem['chan_price'], forthElem['chan_price'])) or\\\n",
    "            (float_more_equal(firstElem['chan_price'], thirdElem['chan_price']) and float_less_equal(secondElem['chan_price'], forthElem['chan_price'])):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_XD_inclusion_free(self, direction, next_valid_elems, working_df):\n",
    "        '''\n",
    "        check the 4 elems are inclusion free by direction, if not operate the inclusion, gaps are defined as pure gap\n",
    "        return two values:\n",
    "        if inclusion free \n",
    "        if kbar gap as xd\n",
    "        '''\n",
    "        if len(next_valid_elems) < 4:\n",
    "            if self.isdebug:\n",
    "                print(\"Invalid number of elems found\")\n",
    "            return False, False\n",
    "        \n",
    "        firstElem = working_df[next_valid_elems[0]]\n",
    "        secondElem = working_df[next_valid_elems[1]]\n",
    "        thirdElem = working_df[next_valid_elems[2]]\n",
    "        forthElem = working_df[next_valid_elems[3]]\n",
    "        tb = 'tb'\n",
    "        chan_price = 'chan_price'\n",
    "        if direction == TopBotType.top2bot:\n",
    "            assert firstElem[tb] == thirdElem[tb] == TopBotType.bot.value and secondElem[tb] == forthElem[tb] == TopBotType.top.value, \"Invalid starting tb status for checking inclusion top2bot: {0}, {1}, {2}, {3}\".format(firstElem, thirdElem, secondElem, forthElem)\n",
    "        elif direction == TopBotType.bot2top:\n",
    "            assert firstElem[tb] == thirdElem[tb] == TopBotType.top.value and  secondElem[tb] == forthElem[tb] == TopBotType.bot.value, \"Invalid starting tb status for checking inclusion bot2top: {0}, {1}, {2}, {3}\".format(firstElem, thirdElem, secondElem, forthElem)       \n",
    "        \n",
    "        if self.xd_inclusion(firstElem, secondElem, thirdElem, forthElem):  \n",
    "            ############################## special case of kline gap as XD ##############################\n",
    "            # only checking if any one node is in pure gap range. The same logic as gap for XD\n",
    "            if self.kbar_gap_as_xd(working_df, next_valid_elems[0], next_valid_elems[1], None) or\\\n",
    "                self.kbar_gap_as_xd(working_df, next_valid_elems[2], next_valid_elems[3], None) or\\\n",
    "                self.kbar_gap_as_xd(working_df, next_valid_elems[1], next_valid_elems[2], None):\n",
    "                if self.isdebug:\n",
    "                    print(\"inclusion ignored due to kline gaps, with loc {0}@{1}, {2}@{3}, {4}@{5}, {6}@{7}\".format(firstElem['date'], \n",
    "                                                                                                                  firstElem['chan_price'],\n",
    "                                                                                                                  secondElem['date'],\n",
    "                                                                                                                  secondElem['chan_price'],\n",
    "                                                                                                                  thirdElem['date'], \n",
    "                                                                                                                  thirdElem['chan_price'],\n",
    "                                                                                                                  forthElem['date'],\n",
    "                                                                                                                  forthElem['chan_price'],\n",
    "                                                                                                                  ))\n",
    "                return True, True\n",
    "            ############################## special case of kline gap as XD ##############################                \n",
    "            \n",
    "            # We need to be careful of which nodes to remove!\n",
    "            removed_loc_1 = removed_loc_2 = 0\n",
    "            if direction == TopBotType.top2bot:\n",
    "                if float_less(firstElem[chan_price], thirdElem[chan_price]):\n",
    "                    working_df[next_valid_elems[1]][tb] = TopBotType.noTopBot.value\n",
    "                    working_df[next_valid_elems[2]][tb] = TopBotType.noTopBot.value\n",
    "                    removed_loc_1 = 1\n",
    "                    removed_loc_2 = 2\n",
    "                else:\n",
    "                    working_df[next_valid_elems[0]][tb] = TopBotType.noTopBot.value\n",
    "                    working_df[next_valid_elems[1]][tb] = TopBotType.noTopBot.value\n",
    "                    removed_loc_1 = 0\n",
    "                    removed_loc_2 = 1\n",
    "            else: # bot2top\n",
    "                if float_more(firstElem[chan_price], thirdElem[chan_price]):\n",
    "                    working_df[next_valid_elems[1]][tb] = TopBotType.noTopBot.value\n",
    "                    working_df[next_valid_elems[2]][tb] = TopBotType.noTopBot.value\n",
    "                    removed_loc_1 = 1\n",
    "                    removed_loc_2 = 2\n",
    "                else:\n",
    "                    working_df[next_valid_elems[0]][tb] = TopBotType.noTopBot.value\n",
    "                    working_df[next_valid_elems[1]][tb] = TopBotType.noTopBot.value\n",
    "                    removed_loc_1 = 0\n",
    "                    removed_loc_2 = 1\n",
    "\n",
    "            \n",
    "            if self.isdebug:\n",
    "                print(\"location {0}@{1}, {2}@{3} removed for combination\".format(working_df[next_valid_elems[removed_loc_1]]['date'], \n",
    "                                                                                 working_df[next_valid_elems[removed_loc_1]][chan_price], \n",
    "                                                                                 working_df[next_valid_elems[removed_loc_2]]['date'], \n",
    "                                                                                 working_df[next_valid_elems[removed_loc_2]][chan_price]))\n",
    "            return False, False\n",
    "        \n",
    "        return True, False\n",
    "    \n",
    "\n",
    "    def check_inclusion_by_direction(self, current_loc, working_df, direction, count_num=6):\n",
    "        '''\n",
    "        count_num can be 4, 6, 8 to suit different needs\n",
    "        '''\n",
    "        i = current_loc\n",
    "        first_run = True\n",
    "\n",
    "#         count_num = 8 if with_gap else 6\n",
    "        # for without gap case we need to make sure all second and third (carry forward as well) \n",
    "        # elem are inclusion free that results 6 nodes to be tested\n",
    "        # for with gap case we need to test all first second and third elem (not carry forward) \n",
    "        # this also results 6 nodes to be tested\n",
    "            \n",
    "        while first_run or (i+count_num-1 < working_df.shape[0]):\n",
    "            first_run = False\n",
    "            \n",
    "            next_valid_elems = self.get_next_N_elem(i, working_df, count_num)\n",
    "            \n",
    "            if len(next_valid_elems) < count_num:\n",
    "                break\n",
    "            \n",
    "            # we need to either get to last layer of is_inclusion_free or any level of is_kline_gap_xd\n",
    "            if count_num == 4:\n",
    "                is_inclusion_free, _ = self.is_XD_inclusion_free(direction, next_valid_elems[:4], working_df)\n",
    "                if is_inclusion_free:\n",
    "                    break\n",
    "            elif count_num == 6:\n",
    "                is_inclusion_free, is_kline_gap_xd = self.is_XD_inclusion_free(direction, next_valid_elems[:4], working_df)\n",
    "                if is_kline_gap_xd:\n",
    "                    break\n",
    "                if is_inclusion_free:\n",
    "                    is_inclusion_free, _ = self.is_XD_inclusion_free(direction, next_valid_elems[-4:], working_df)\n",
    "                    if is_inclusion_free:\n",
    "                        break\n",
    "            else: #count_num == 8:\n",
    "                is_inclusion_free, is_kline_gap_xd = self.is_XD_inclusion_free(direction, next_valid_elems[:4], working_df)\n",
    "                if is_kline_gap_xd:\n",
    "                    break\n",
    "                if is_inclusion_free:\n",
    "                    is_inclusion_free, is_kline_gap_xd = self.is_XD_inclusion_free(direction, next_valid_elems[2:6], working_df)\n",
    "                    if is_kline_gap_xd:\n",
    "                        break\n",
    "                    if is_inclusion_free:\n",
    "                        is_inclusion_free, _ = self.is_XD_inclusion_free(direction, next_valid_elems[-4:], working_df)\n",
    "                        if is_inclusion_free:\n",
    "                            break\n",
    "        return next_valid_elems\n",
    "                \n",
    "\n",
    "    def check_current_gap(self, first, second, third, forth):\n",
    "        '''\n",
    "        giving the first four elem, find out if current gap exists\n",
    "        '''\n",
    "        tb = 'tb'\n",
    "        chan_price = 'chan_price'\n",
    "        with_gap = False\n",
    "        if third[tb] == TopBotType.top.value:\n",
    "            with_gap = float_less(first[chan_price], forth[chan_price])\n",
    "        elif third[tb] == TopBotType.bot.value:\n",
    "            with_gap = float_more(first[chan_price], forth[chan_price])\n",
    "        else:\n",
    "            print(\"Error, invalid tb status!\")\n",
    "        return with_gap\n",
    "\n",
    "    def check_XD_topbot(self, first, second, third, forth, fifth, sixth):\n",
    "        '''\n",
    "        check if current 5 BI (6 bi tb) form XD top or bot\n",
    "        check if gap between first and third BI\n",
    "        '''\n",
    "        tb = 'tb'\n",
    "        chan_price = 'chan_price'\n",
    "        assert first[tb] == third[tb] == fifth[tb] and second[tb] == forth[tb] == sixth[tb], \"invalid tb status!\"\n",
    "        \n",
    "        result_status = TopBotType.noTopBot\n",
    "        with_gap = False\n",
    "        \n",
    "        if third[tb] == TopBotType.top.value:\n",
    "            with_gap = float_less(first[chan_price], forth[chan_price])\n",
    "            if float_more(third[chan_price], first[chan_price]) and\\\n",
    "             float_more(third[chan_price], fifth[chan_price]) and\\\n",
    "             float_more(forth[chan_price], sixth[chan_price]):\n",
    "                result_status = TopBotType.top\n",
    "                \n",
    "        elif third[tb] == TopBotType.bot.value:\n",
    "            with_gap = float_more(first[chan_price], forth[chan_price])\n",
    "            if float_less(third[chan_price], first[chan_price]) and\\\n",
    "             float_less(third[chan_price], fifth[chan_price]) and\\\n",
    "             float_less(forth[chan_price], sixth[chan_price]):\n",
    "                result_status = TopBotType.bot\n",
    "                            \n",
    "        else:\n",
    "            print(\"Error, invalid tb status!\")\n",
    "        \n",
    "        return result_status, with_gap\n",
    "    \n",
    "\n",
    "    def check_kline_gap_as_xd(self, next_valid_elems, working_df, direction):\n",
    "        first = working_df[next_valid_elems[0]]\n",
    "        second = working_df[next_valid_elems[1]]\n",
    "        third = working_df[next_valid_elems[2]]\n",
    "        forth = working_df[next_valid_elems[3]]\n",
    "        fifth = working_df[next_valid_elems[4]]\n",
    "        xd_gap_result = TopBotType.noTopBot\n",
    "        without_gap = False\n",
    "        with_kline_gap_as_xd = False\n",
    "\n",
    "        # check the corner case where xd can be formed by a single kline gap\n",
    "        # if kline gap (from original data) exists between second and third or third and forth\n",
    "        # A if so only check if third is top or bot comparing with first, \n",
    "        # B with_gap is determined by checking if the kline gap range cover between first and forth\n",
    "        # C change direction as usual, and increment counter by 1 only\n",
    "        chan_price = 'chan_price'\n",
    "        if not self.previous_with_xd_gap and\\\n",
    "            self.kbar_gap_as_xd(working_df, next_valid_elems[2], next_valid_elems[3], next_valid_elems[1]):\n",
    "            without_gap = with_kline_gap_as_xd = True\n",
    "            self.previous_with_xd_gap = True\n",
    "            if self.isdebug:\n",
    "                print(\"XD represented by kline gap 2, {0}, {1}\".format(working_df[next_valid_elems[2]]['date'], working_df[next_valid_elems[3]]['date']))\n",
    "        \n",
    "        if not with_kline_gap_as_xd and self.previous_with_xd_gap:\n",
    "            self.previous_with_xd_gap=False # close status\n",
    "            if self.kbar_gap_as_xd(working_df, next_valid_elems[1], next_valid_elems[2], next_valid_elems[0]):\n",
    "                without_gap = with_kline_gap_as_xd = True\n",
    "                if self.isdebug:\n",
    "                    print(\"XD represented by kline gap 1, {0}, {1}\".format(working_df[next_valid_elems[1]]['date'], working_df[next_valid_elems[2]]['date']))\n",
    "\n",
    "        if with_kline_gap_as_xd: # we don't need to compare with the first elem\n",
    "            if (direction == TopBotType.bot2top and float_more(third[chan_price], fifth[chan_price])): #and float_more(third[chan_price], first[chan_price])\n",
    "                xd_gap_result = TopBotType.top\n",
    "            elif (direction == TopBotType.top2bot and float_less(third[chan_price], fifth[chan_price])): #and float_less(third[chan_price], first[chan_price]) \n",
    "                xd_gap_result = TopBotType.bot\n",
    "            else:\n",
    "                if self.isdebug:\n",
    "                    print(\"XD represented by kline gap 3\")\n",
    "        \n",
    "        return xd_gap_result, not without_gap, with_kline_gap_as_xd\n",
    "    \n",
    "    \n",
    "    def check_previous_elem_to_avoid_xd_gap(self, with_gap, next_valid_elems, working_df):\n",
    "        tb = 'tb'\n",
    "        chan_price = 'chan_price'\n",
    "        first = working_df[next_valid_elems[0]]\n",
    "        forth = working_df[next_valid_elems[3]]\n",
    "        previous_elem = self.get_previous_N_elem(next_valid_elems[0], \n",
    "                                                 working_df, \n",
    "                                                 N=0, \n",
    "                                                 end_tb=TopBotType.value2type(first[tb]), \n",
    "                                                 single_direction=True)\n",
    "        if len(previous_elem) >= 1: # use single direction at least 1 needed\n",
    "            if first[tb] == TopBotType.top.value:\n",
    "                with_gap = float_less(working_df[previous_elem][chan_price].max(), forth[chan_price])\n",
    "            elif first[tb] == TopBotType.bot.value:\n",
    "                with_gap = float_more(working_df[previous_elem][chan_price].min(), forth[chan_price])\n",
    "            else:\n",
    "                assert first[tb] == TopBotType.top.value or first[tb] == TopBotType.bot.value, \"Invalid first elem tb\"\n",
    "        if not with_gap and self.isdebug:\n",
    "            print(\"elem gap unchecked at {0}\".format(working_df[next_valid_elems[0]]['date']))\n",
    "        return with_gap  \n",
    "    \n",
    "    def check_XD_topbot_directed(self, next_valid_elems, direction, working_df):\n",
    "        first = working_df[next_valid_elems[0]]\n",
    "        second = working_df[next_valid_elems[1]]\n",
    "        third = working_df[next_valid_elems[2]]\n",
    "        forth = working_df[next_valid_elems[3]]\n",
    "        fifth = working_df[next_valid_elems[4]]\n",
    "        sixth = working_df[next_valid_elems[5]]     \n",
    "        with_kline_gap_as_xd = False\n",
    "        \n",
    "        xd_gap_result, with_current_gap, with_kline_gap_as_xd = self.check_kline_gap_as_xd(next_valid_elems, working_df, direction)\n",
    "        \n",
    "        if with_kline_gap_as_xd and xd_gap_result != TopBotType.noTopBot:\n",
    "            return xd_gap_result, with_current_gap, with_kline_gap_as_xd\n",
    "        \n",
    "        result, with_current_gap = self.check_XD_topbot(first, second, third, forth, fifth, sixth)\n",
    "        \n",
    "        if (result == TopBotType.top and direction == TopBotType.bot2top) or (result == TopBotType.bot and direction == TopBotType.top2bot):\n",
    "            if with_current_gap: # check previous elements to see if the gap can be closed TESTED!\n",
    "                with_current_gap = self.check_previous_elem_to_avoid_xd_gap(with_current_gap, next_valid_elems, working_df)\n",
    "            return result, with_current_gap, with_kline_gap_as_xd\n",
    "        else:\n",
    "            return TopBotType.noTopBot, with_current_gap, with_kline_gap_as_xd\n",
    "        \n",
    "    def defineXD(self, initial_status=TopBotType.noTopBot):\n",
    "        working_df = self.kDataFrame_marked[['date', 'close', 'high', 'low', 'chan_price', 'tb','real_loc']] # real_loc used for central region\n",
    "        \n",
    "        working_df = append_fields(working_df,\n",
    "                                   ['original_tb', 'xd_tb'],\n",
    "                                   [working_df['tb'], [TopBotType.noTopBot.value] * working_df.size],\n",
    "                                   usemask=False)\n",
    "\n",
    "        if working_df.size==0:\n",
    "            self.kDataFrame_xd = working_df\n",
    "            return working_df\n",
    "    \n",
    "        # find initial direction\n",
    "        initial_i, initial_direction = self.find_initial_direction(working_df, initial_status)\n",
    "        \n",
    "        # loop through to find XD top bot\n",
    "        working_df = self.find_XD(initial_i, initial_direction, working_df)\n",
    "        \n",
    "        working_df = working_df[(working_df['xd_tb']==TopBotType.top.value) | (working_df['xd_tb']==TopBotType.bot.value)]\n",
    "            \n",
    "        self.kDataFrame_xd = working_df[FEN_DUAN_COLUMNS]\n",
    "        if self.isdebug:\n",
    "            print(\"self.kDataFrame_xd:{0}\".format(self.kDataFrame_xd))\n",
    "        return working_df\n",
    "    \n",
    "    def get_next_N_elem(self, loc, working_df, N=4, start_tb=TopBotType.noTopBot, single_direction=False):\n",
    "        '''\n",
    "        get the next N number of elems if tb isn't noTopBot, \n",
    "        if start_tb is set, find the first N number of elems starting with tb given\n",
    "        starting from loc(inclusive)\n",
    "        '''\n",
    "        i = loc\n",
    "        result_locs = []\n",
    "        while i < working_df.size:\n",
    "            current_elem = working_df[i]\n",
    "            if current_elem['tb'] != TopBotType.noTopBot.value:\n",
    "                if start_tb != TopBotType.noTopBot and current_elem['tb'] != start_tb.value and len(result_locs) == 0:\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                if single_direction and current_elem['tb'] != start_tb.value:\n",
    "                    i = i + 1\n",
    "                    continue\n",
    "                result_locs.append(i)\n",
    "                if len(result_locs) == N:\n",
    "                    break\n",
    "            i = i + 1\n",
    "        return result_locs\n",
    "    \n",
    "    \n",
    "    def get_previous_N_elem(self, loc, working_df, N=0, end_tb=TopBotType.noTopBot, single_direction=True):\n",
    "        '''\n",
    "        get the previous N number of elems if tb isn't noTopBot, \n",
    "        if start_tb is set, find the first N number of elems ending with tb given (order preserved)\n",
    "        ending with loc (exclusive)\n",
    "        We are only expecting elem from the same XD, meaning the same direction. So we fetch upto previous xd_tb if N == 0\n",
    "        single_direction meaning only return elem with the same tb as end_tb\n",
    "        We are checking the original_tb field to avoid BI been combined. \n",
    "        This function is only used for xd gap check\n",
    "        '''\n",
    "        i = loc-1\n",
    "        result_locs = []\n",
    "        while i >= 0:\n",
    "            current_elem = working_df[i]\n",
    "            if current_elem['original_tb'] != TopBotType.noTopBot.value:\n",
    "                if end_tb != TopBotType.noTopBot and current_elem['original_tb'] != end_tb.value and len(result_locs) == 0:\n",
    "                    i = i - 1\n",
    "                    continue\n",
    "                if single_direction: \n",
    "                    if current_elem['original_tb'] == end_tb.value:\n",
    "                        result_locs.insert(0, i)\n",
    "                else:\n",
    "                    result_locs.insert(0, i)\n",
    "                if N != 0 and len(result_locs) == N:\n",
    "                    break\n",
    "                if N == 0 and (current_elem['xd_tb'] == TopBotType.top.value or current_elem['xd_tb'] == TopBotType.bot.value):\n",
    "                    break\n",
    "            i = i - 1\n",
    "        return result_locs\n",
    "    \n",
    "    def xd_topbot_candidate(self, next_valid_elems, current_direction, working_df, with_current_gap):\n",
    "        '''\n",
    "        check current candidates BIs are positioned as idx is at tb\n",
    "        we are only expecting newly found index to move forward\n",
    "        \n",
    "        added extra check after inclusion done\n",
    "        '''\n",
    "        result = None\n",
    "        \n",
    "        # simple check\n",
    "        if len(next_valid_elems) != 3 and self.isdebug:\n",
    "            print(\"Invalid number of tb elem passed in\")\n",
    "        \n",
    "        chan_price_list = [working_df[nv]['chan_price'] for nv in next_valid_elems]\n",
    "            \n",
    "        if current_direction == TopBotType.top2bot:\n",
    "            min_value = min(chan_price_list) \n",
    "            min_index = chan_price_list.index(min_value)  \n",
    "            if min_index > 1: # ==2\n",
    "                result = next_valid_elems[min_index-1] # navigate to the starting for current bot\n",
    "             \n",
    "        elif current_direction == TopBotType.bot2top:\n",
    "            max_value = max(chan_price_list) \n",
    "            max_index = chan_price_list.index(max_value)\n",
    "            if max_index > 1:\n",
    "                result = next_valid_elems[max_index-1] # navigate to the starting for current bot\n",
    "        \n",
    "        if result is not None:\n",
    "            return result\n",
    "        \n",
    "        # check with inclusion\n",
    "        if with_current_gap:\n",
    "            new_valid_elems = self.check_inclusion_by_direction(next_valid_elems[1], working_df, current_direction, count_num=4)\n",
    "        else:\n",
    "            new_valid_elems = self.check_inclusion_by_direction(next_valid_elems[1], working_df, current_direction, count_num=6)\n",
    "        \n",
    "        # we only care about the next 4 elements there goes 0 -> 3\n",
    "        end_loc = new_valid_elems[3]+1 if len(new_valid_elems) >= 4 else None\n",
    "        affected_chan_prices = working_df[new_valid_elems[0]:end_loc]['chan_price']\n",
    "        \n",
    "        if current_direction == TopBotType.top2bot:\n",
    "            min_price = min(affected_chan_prices)\n",
    "            if float_less(min_price, working_df[next_valid_elems[1]]['chan_price']):\n",
    "                result = next_valid_elems[1] # next candidate\n",
    "        else:\n",
    "            max_price = max(affected_chan_prices)\n",
    "            if float_more(max_price, working_df[next_valid_elems[1]]['chan_price']):\n",
    "                result = next_valid_elems[1]\n",
    "        \n",
    "        if result is not None: # restore data\n",
    "#             working_df[next_valid_elems[1]:new_valid_elems[-1]]['tb'] = working_df[next_valid_elems[1]:new_valid_elems[-1]]['original_tb']\n",
    "#             if self.isdebug:\n",
    "#                 print(\"tb data restored from {0} to {1} real_loc {2} to {3}\".format(working_df[next_valid_elems[1]]['date'], \n",
    "#                                                                                     working_df[new_valid_elems[-1]]['date'], \n",
    "#                                                                                     working_df[next_valid_elems[1]]['real_loc'], \n",
    "#                                                                                     working_df[new_valid_elems[-1]]['real_loc']))\n",
    "            self.restore_tb_data(working_df, next_valid_elems[1], new_valid_elems[-1])\n",
    "        return result\n",
    "    \n",
    "    def restore_tb_data(self, working_df, from_idx, to_idx):\n",
    "        working_df[from_idx:to_idx]['tb'] = working_df[from_idx:to_idx]['original_tb']\n",
    "        if self.isdebug:\n",
    "            print(\"tb data restored from {0} to {1} real_loc {2} to {3}\".format(working_df[from_idx]['date'], \n",
    "                                                                                working_df[to_idx if to_idx is not None else -1]['date'], \n",
    "                                                                                working_df[from_idx]['real_loc'], \n",
    "                                                                                working_df[to_idx if to_idx is not None else -1]['real_loc']))\n",
    " \n",
    "    \n",
    "    def pop_gap(self, working_df, next_valid_elems, current_direction):\n",
    "        chan_price = 'chan_price'\n",
    "        tb = 'tb'\n",
    "        original_tb = 'original_tb'\n",
    "        xd_tb='xd_tb'\n",
    "        date='date'\n",
    "        real_loc='real_loc'\n",
    "        i = None\n",
    "        #################### pop gap_XD ##########################\n",
    "        checking_elems_price = working_df[next_valid_elems[0]:next_valid_elems[-1]+1][chan_price]\n",
    "        \n",
    "        previous_gap_elem = working_df[self.gap_XD[-1]]\n",
    "        if current_direction == TopBotType.top2bot:\n",
    "            if float_more(max(checking_elems_price), previous_gap_elem[chan_price]):\n",
    "                previous_gap_loc = self.gap_XD.pop()\n",
    "                if self.isdebug:\n",
    "                    print(\"xd_tb cancelled due to new high found: {0} {1}\".format(working_df[previous_gap_loc][date], working_df[previous_gap_loc][real_loc]))\n",
    "                working_df[previous_gap_loc][xd_tb] = TopBotType.noTopBot.value\n",
    "                \n",
    "                self.restore_tb_data(working_df, previous_gap_loc, next_valid_elems[-1])\n",
    "                current_direction = TopBotType.reverse(current_direction)\n",
    "                if self.isdebug:\n",
    "                    print(\"gap closed 1:{0}, {1}\".format(working_df[previous_gap_loc][date], TopBotType.value2type(working_df[previous_gap_loc][tb]))) \n",
    "                    [print(\"gap info 3:{0}, {1}\".format(working_df[gap_loc][date], TopBotType.value2type(working_df[gap_loc][tb]))) for gap_loc in self.gap_XD]\n",
    "                i = previous_gap_loc\n",
    "                \n",
    "        elif current_direction == TopBotType.bot2top:\n",
    "            if float_less(min(checking_elems_price), previous_gap_elem[chan_price]):\n",
    "                previous_gap_loc = self.gap_XD.pop()\n",
    "                if self.isdebug:\n",
    "                    print(\"xd_tb cancelled due to new low found: {0} {1}\".format(working_df[previous_gap_loc][date], working_df[previous_gap_loc][real_loc]))\n",
    "                working_df[previous_gap_loc][xd_tb] = TopBotType.noTopBot.value\n",
    "                \n",
    "                self.restore_tb_data(working_df, previous_gap_loc, next_valid_elems[-1])\n",
    "                current_direction = TopBotType.reverse(current_direction)\n",
    "                if self.isdebug:\n",
    "                    print(\"gap closed 2:{0}, {1}\".format(working_df[previous_gap_loc][date],  TopBotType.value2type(working_df[previous_gap_loc][tb])))\n",
    "                    [print(\"gap info 3:{0}, {1}\".format(working_df[gap_loc][date], TopBotType.value2type(working_df[gap_loc][tb]))) for gap_loc in self.gap_XD]\n",
    "                i = previous_gap_loc\n",
    "        return i, current_direction\n",
    "        #################### pop gap_XD ##########################\n",
    "\n",
    "    def find_XD(self, initial_i, initial_direction, working_df):\n",
    "        real_loc = 'real_loc'\n",
    "        xd_tb = 'xd_tb'\n",
    "        date = 'date'\n",
    "        chan_price = 'chan_price'\n",
    "        tb = 'tb'\n",
    "        original_tb = 'original_tb'\n",
    "        if self.isdebug:\n",
    "            print(\"Initial direction {0} at location {1} with real_loc {2}\".format(initial_direction, initial_i, working_df[initial_i][real_loc]))\n",
    "        \n",
    "        current_direction = initial_direction  \n",
    "        i = initial_i\n",
    "        while i+5 < working_df.size:\n",
    "            \n",
    "            if self.isdebug:\n",
    "                print(\"working at {0}, {1}, {2}, {3}, {4}\".format(working_df[i][date], \n",
    "                                                                  working_df[i][chan_price], \n",
    "                                                                  current_direction, \n",
    "                                                                  working_df[i][real_loc], \n",
    "                                                                  TopBotType.value2type(working_df[i][tb])))\n",
    "            \n",
    "            previous_gap = len(self.gap_XD) != 0\n",
    "            \n",
    "            if previous_gap:\n",
    "                # do inclusion find the next two elems we need to do inclusion as we have previous gaps\n",
    "                next_valid_elems= self.check_inclusion_by_direction(i, working_df, current_direction, count_num=4)\n",
    "                if len(next_valid_elems) < 4:\n",
    "                    break\n",
    "                # make sure we are checking the right elem by direction\n",
    "                if not self.direction_assert(working_df[next_valid_elems[0]], current_direction):\n",
    "                    i = next_valid_elems[1]\n",
    "                    continue\n",
    "                # check if we have current gap\n",
    "                current_gap = self.check_current_gap(working_df[next_valid_elems[0]],\n",
    "                                                     working_df[next_valid_elems[1]],\n",
    "                                                     working_df[next_valid_elems[2]],\n",
    "                                                     working_df[next_valid_elems[3]])\n",
    "                \n",
    "                # based on current gap info, we find the next elems\n",
    "                if current_gap: \n",
    "                    next_valid_elems= self.check_inclusion_by_direction(next_valid_elems[0], working_df, current_direction, count_num=6)\n",
    "                else:\n",
    "                    next_valid_elems= self.check_inclusion_by_direction(next_valid_elems[0], working_df, current_direction, count_num=8)\n",
    "                \n",
    "                if len(next_valid_elems) < 6:\n",
    "                    break\n",
    "                \n",
    "                # due to kline gap as xd reasons we do check the current gap again\n",
    "                current_status, with_current_gap, with_kline_gap_as_xd = self.check_XD_topbot_directed(next_valid_elems, current_direction, working_df)  \n",
    "\n",
    "                if current_status != TopBotType.noTopBot:\n",
    "                    if with_current_gap:\n",
    "                        # save existing gapped Ding/Di\n",
    "                        self.gap_XD.append(next_valid_elems[2])\n",
    "                        \n",
    "                        if self.isdebug:\n",
    "                            [print(\"gap info 1:{0}, {1}\".format(working_df[gap_loc][date], TopBotType.value2type(working_df[gap_loc][tb]))) for gap_loc in self.gap_XD]\n",
    "                        \n",
    "                    else:\n",
    "                        # fixed Ding/Di, clear the record\n",
    "                        self.gap_XD = []\n",
    "                        if self.isdebug:\n",
    "                            print(\"gap cleaned!\")\n",
    "                    working_df[next_valid_elems[2]][xd_tb] = current_status.value\n",
    "                    if self.isdebug:\n",
    "                        print(\"xd_tb located {0} {1}\".format(working_df[next_valid_elems[2]][date], working_df[next_valid_elems[2]][chan_price]))\n",
    "                    current_direction = TopBotType.top2bot if current_status == TopBotType.top else TopBotType.bot2top\n",
    "                    i = next_valid_elems[1] if with_kline_gap_as_xd else next_valid_elems[3]\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    i, current_direction = self.pop_gap(working_df, next_valid_elems, current_direction)\n",
    "                    if i is not None:\n",
    "                        continue\n",
    "                \n",
    "                    i = next_valid_elems[2]\n",
    "            else:    # no gap case\n",
    "                # find next 4 elems, we don't do inclusion as there were no gap previously\n",
    "                next_elems = self.get_next_N_elem(i, working_df, 4)\n",
    "                if len(next_elems) < 4:\n",
    "                    break\n",
    "                \n",
    "                # check if we have current gap\n",
    "                current_gap = self.check_current_gap(working_df[next_elems[0]],\n",
    "                                                     working_df[next_elems[1]],\n",
    "                                                     working_df[next_elems[2]],\n",
    "                                                     working_df[next_elems[3]])\n",
    "                \n",
    "                # find next 3 elems with the same tb info\n",
    "                next_single_direction_elems = self.get_next_N_elem(i, working_df, 3, start_tb = TopBotType.top if current_direction == TopBotType.bot2top else TopBotType.bot, single_direction=True)\n",
    "                \n",
    "                # make sure we are checking the right elem by direction\n",
    "                if not self.direction_assert(working_df[next_single_direction_elems[0]], current_direction):\n",
    "                    i = next_elems[1]\n",
    "                    continue\n",
    "                \n",
    "                # make sure we are targetting the min/max by direction\n",
    "                possible_xd_tb_idx = self.xd_topbot_candidate(next_single_direction_elems, current_direction, working_df, current_gap)\n",
    "                if possible_xd_tb_idx is not None:\n",
    "                    i = possible_xd_tb_idx\n",
    "                    continue\n",
    "                \n",
    "                # find next 6 elems with both direction\n",
    "                next_valid_elems = self.get_next_N_elem(next_single_direction_elems[0], working_df, 6)\n",
    "                if len(next_valid_elems) < 6:\n",
    "                    break  \n",
    "                \n",
    "                current_status, with_current_gap, with_kline_gap_as_xd = self.check_XD_topbot_directed(next_valid_elems, current_direction, working_df)\n",
    "                \n",
    "                if current_status != TopBotType.noTopBot:\n",
    "                    previous_xd_tb_idx = self.get_previous_N_elem(next_valid_elems[0], \n",
    "                                                                  working_df, \n",
    "                                                                  N=0, \n",
    "                                                                  end_tb=TopBotType.reverse(current_status), \n",
    "                                                                  single_direction=True)\n",
    "                    if previous_xd_tb_idx:\n",
    "                        previous_xd_tb_idx = previous_xd_tb_idx[0]\n",
    "                        if ((working_df[previous_xd_tb_idx][xd_tb] == TopBotType.top.value and\\\n",
    "                            current_status == TopBotType.bot and\\\n",
    "                            float_less(working_df[previous_xd_tb_idx][chan_price], working_df[next_valid_elems[2]][chan_price])) or\\\n",
    "                            (working_df[previous_xd_tb_idx][xd_tb] == TopBotType.bot.value and\\\n",
    "                            current_status == TopBotType.top and\\\n",
    "                            float_more(working_df[previous_xd_tb_idx][chan_price], working_df[next_valid_elems[2]][chan_price]))):\n",
    "                            if self.isdebug:\n",
    "                                print(\"current TB not VALID by price with previous TB retrack to {0}\".format(working_df[previous_xd_tb_idx][date]))\n",
    "                            self.restore_tb_data(working_df, previous_xd_tb_idx, next_valid_elems[-1])\n",
    "                            \n",
    "                            working_df[previous_xd_tb_idx][xd_tb] = TopBotType.noTopBot.value\n",
    "                            if self.isdebug:\n",
    "                                print(\"{0} {1} cancelled due to higher bot/lower top found\".format(working_df[previous_xd_tb_idx][date], \n",
    "                                                                                                   TopBotType.value2type(working_df[previous_xd_tb_idx][xd_tb])))\n",
    "                            current_direction = TopBotType.top2bot if current_status == TopBotType.top else TopBotType.bot2top\n",
    "                            i = previous_xd_tb_idx\n",
    "                            continue\n",
    "                    \n",
    "                    if with_current_gap:\n",
    "                        # save existing gapped Ding/Di\n",
    "                        self.gap_XD.append(next_valid_elems[2])\n",
    "                        if self.isdebug:\n",
    "                            [print(\"gap info 4:{0}, {1}\".format(working_df[gap_loc][date], TopBotType.value2type(working_df[gap_loc][tb]))) for gap_loc in self.gap_XD]\n",
    "                    else:\n",
    "                        # cleanest case\n",
    "                        pass\n",
    "                    \n",
    "                    working_df[next_valid_elems[2]][xd_tb] = current_status.value\n",
    "                    if self.isdebug:\n",
    "                        print(\"xd_tb located {0} {1}\".format(working_df[next_valid_elems[2]][date], working_df[next_valid_elems[2]][chan_price]))\n",
    "                        \n",
    "                    current_direction = TopBotType.top2bot if current_status == TopBotType.top else TopBotType.bot2top\n",
    "                    i = next_valid_elems[1] if with_kline_gap_as_xd else next_valid_elems[3]\n",
    "                    continue\n",
    "                else:\n",
    "                    i = next_valid_elems[2]\n",
    "                    \n",
    "        # We need to deal with the remaining BI tb and make an assumption that current XD ends\n",
    "\n",
    "        # + 3 to make sure we have 3 BI at least in XD\n",
    "        previous_xd_tb_locs = self.get_previous_N_elem(working_df.shape[0]-1, working_df, N=0, single_direction=False)\n",
    "        if previous_xd_tb_locs:\n",
    "            pre_pre_xd_tb_locs = self.get_previous_N_elem(previous_xd_tb_locs[0], working_df, N=0, single_direction=False)\n",
    "            columns = ['date', chan_price, tb, original_tb]\n",
    "            previous_xd_tb_loc = previous_xd_tb_locs[0]\n",
    "            working_xd_tb_loc = previous_xd_tb_loc+3\n",
    "            \n",
    "            if working_xd_tb_loc < working_df.shape[0]:\n",
    "                # restore tb info from loc found from original_tb as we don't need them?\n",
    "#                 self.restore_tb_data(working_df, working_xd_tb_loc, None)\n",
    "                \n",
    "                temp_df = working_df[working_xd_tb_loc:][columns]\n",
    "                if temp_df.size > 0:\n",
    "                    temp_df = temp_df[temp_df[tb] != TopBotType.noTopBot.value]\n",
    "                    gapped_change = False\n",
    "                    if self.gap_XD: \n",
    "                        # with gap we check if there is higher/lower tb for xd_tb\n",
    "                        if current_direction == TopBotType.top2bot:\n",
    "                            max_loc = temp_df[chan_price].argmax()\n",
    "                            max_date = temp_df[max_loc][date]\n",
    "                            max_price = temp_df[max_loc][chan_price]\n",
    "                            working_loc = np.where(working_df[date]==max_date)[0][0]\n",
    "                            if float_more(max_price, working_df[previous_xd_tb_loc][chan_price]):\n",
    "                                working_df[previous_xd_tb_loc][xd_tb] = TopBotType.noTopBot.value\n",
    "                                working_df[working_loc][xd_tb] = TopBotType.top.value\n",
    "                                gapped_change = True\n",
    "                            if self.isdebug:\n",
    "                                print(\"final gapped xd_tb located from {0} for {1}\".format(max_date, TopBotType.top))\n",
    "                        elif current_direction == TopBotType.bot2top:\n",
    "                            min_loc = temp_df[chan_price].argmin()\n",
    "                            min_date = temp_df[min_loc][date]\n",
    "                            min_price = temp_df[min_loc][chan_price]\n",
    "                            working_loc = np.where(working_df[date]==min_date)[0][0]\n",
    "                            if float_less(min_price, working_df[previous_xd_tb_loc][chan_price]):\n",
    "                                working_df[previous_xd_tb_loc][xd_tb] = TopBotType.noTopBot.value\n",
    "                                working_df[working_loc][xd_tb] = TopBotType.bot.value\n",
    "                                gapped_change = True\n",
    "                            if self.isdebug:\n",
    "                                print(\"final gapped xd_tb located from {0} for {1}\".format(min_date, TopBotType.bot))\n",
    "                    \n",
    "                        if gapped_change:\n",
    "                            working_xd_tb_loc = working_loc+3\n",
    "                            previous_xd_tb_loc = working_loc\n",
    "                            temp_df = working_df[working_xd_tb_loc:][columns]\n",
    "                        \n",
    "                    # We could make an assumption based on assumption. \n",
    "                    if temp_df.size > 0:\n",
    "                        max_price = temp_df[chan_price].max()\n",
    "                        min_price = temp_df[chan_price].min()\n",
    "                        \n",
    "                        if current_direction == TopBotType.top2bot:\n",
    "                            # only make guess if previous xd ding is the highest so far\n",
    "                            if float_more(working_df[previous_xd_tb_loc][chan_price], max_price) or\\\n",
    "                                (pre_pre_xd_tb_locs and float_more(working_df[pre_pre_xd_tb_locs[0]][chan_price], min_price)):\n",
    "                                min_loc = temp_df[chan_price].argmin()\n",
    "                                min_date = temp_df[min_loc][date]\n",
    "                                working_loc = np.where(working_df[date]==min_date)[0][0]\n",
    "                                working_df[working_loc][xd_tb] = TopBotType.bot.value\n",
    "                                if self.isdebug:\n",
    "                                    print(\"final xd_tb located from {0} for {1}\".format(min_date, TopBotType.bot))\n",
    "                            elif float_less(working_df[previous_xd_tb_loc][chan_price], max_price):\n",
    "                                max_loc = temp_df[chan_price].argmax()\n",
    "                                max_date = temp_df[max_loc][date]\n",
    "                                working_loc = np.where(working_df[date]==max_date)[0][0]\n",
    "                                working_df[working_loc][xd_tb] = TopBotType.top.value\n",
    "                                working_df[previous_xd_tb_loc][xd_tb] = TopBotType.noTopBot.value\n",
    "                                if self.isdebug:\n",
    "                                    print(\"final xd_tb located from {0} for {1}, replacing {2}\".format(max_date, \n",
    "                                                                                                   TopBotType.top,\n",
    "                                                                                                   working_df[previous_xd_tb_loc][date]))\n",
    "                        elif current_direction == TopBotType.bot2top:\n",
    "                            # only make guess if previous xd di is the lowest so far\n",
    "                            if float_less(working_df[previous_xd_tb_loc][chan_price], min_price) or\\\n",
    "                                (pre_pre_xd_tb_locs and float_less(working_df[pre_pre_xd_tb_locs[0]][chan_price], max_price)):\n",
    "                                max_loc = temp_df[chan_price].argmax()\n",
    "                                max_date = temp_df[max_loc][date]\n",
    "                                working_loc = np.where(working_df[date]==max_date)[0][0]\n",
    "                                working_df[working_loc][xd_tb] = TopBotType.top.value\n",
    "                                if self.isdebug:\n",
    "                                    print(\"final xd_tb located from {0} for {1}\".format(max_date, TopBotType.top))\n",
    "                            elif float_more(working_df[previous_xd_tb_loc][chan_price], min_price):\n",
    "                                min_loc = temp_df[chan_price].argmin()\n",
    "                                min_date = temp_df[min_loc][date]\n",
    "                                working_loc = np.where(working_df[date]==min_date)[0][0]\n",
    "                                working_df[working_loc][xd_tb] = TopBotType.bot.value\n",
    "                                working_df[previous_xd_tb_loc][xd_tb] = TopBotType.noTopBot.value\n",
    "                                if self.isdebug:\n",
    "                                    print(\"final xd_tb located from {0} for {1}, replacing {2}\".format(min_date, \n",
    "                                                                                                   TopBotType.bot,\n",
    "                                                                                                   working_df[previous_xd_tb_loc][date]))\n",
    "                        else:\n",
    "                            print(\"Invalid direction\")\n",
    "                else:\n",
    "                    print(\"empty temp_df, continue\")\n",
    "        \n",
    "        return working_df\n",
    "                \n",
    "    def direction_assert(self, firstElem, direction):\n",
    "        # make sure we are checking the right elem by direction\n",
    "        result = True\n",
    "        if direction == TopBotType.top2bot:\n",
    "            if firstElem['tb'] != TopBotType.bot.value:\n",
    "                print(\"We have invalid elem tb value: {0}\".format(firstElem['tb']))\n",
    "                result = False\n",
    "        elif direction == TopBotType.bot2top:\n",
    "            if firstElem['tb'] != TopBotType.top.value:\n",
    "                print(\"We have invalid elem tb value: {0}\".format(firstElem['tb']))\n",
    "                result = False\n",
    "        else:\n",
    "            result = False\n",
    "            print(\"We have invalid direction value!!!!!\")\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/recfunctions.py:430: FutureWarning: Numpy has detected that you may be viewing or writing to an array returned by selecting multiple fields in a structured array. \n",
      "\n",
      "This code may break in numpy 1.15 because this will return a view instead of a copy -- see release notes for details.\n",
      "  return seqarrays.view(dtype=seqdtype, type=seqtype)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/recfunctions.py:672: FutureWarning: Numpy has detected that you may be viewing or writing to an array returned by selecting multiple fields in a structured array. \n",
      "\n",
      "This code may break in numpy 1.15 because this will return a view instead of a copy -- see release notes for details.\n",
      "  data = [a.view([(name, a.dtype)]) for (name, a) in zip(names, data)]\n"
     ]
    }
   ],
   "source": [
    "# 缠论笔，线段画图\n",
    "import pandas as pd\n",
    "from pyecharts import Line, Overlap, Kline\n",
    "from pyecharts import configure\n",
    "configure(global_theme='dark')\n",
    "\n",
    "def draw_chan(stock, stock_df_fenduan, stock_df, kc, end_time): #\n",
    "    stock_df_original = stock_df[['date', 'open', 'close', 'low', 'high']]\n",
    "    stock_df_bi = kc.getFenBI_df()[['date','chan_price']]\n",
    "    stock_df_xd = kc.getFenDuan_df()[['date','chan_price']]\n",
    "    \n",
    "    \n",
    "    overlap = Overlap(width=1500, height=600)\n",
    "    overlap.use_theme( \"dark\")\n",
    " \n",
    "    kline = Kline(\"缠论\")\n",
    "    kline.use_theme( \"dark\")\n",
    "    kline.add(stock, \n",
    "              stock_df_original['date'].tolist(), \n",
    "              stock_df_original[['open', 'close', 'low', 'high']].tolist(), \n",
    "              is_datazoom_show=True,\n",
    "              datazoom_type=\"both\",\n",
    "              datazoom_range=[80,100], \n",
    "              xaxis_interval=10,\n",
    "              xaxis_rotate=30, \n",
    "              background_color='black')\n",
    "    overlap.add(kline)\n",
    "\n",
    "    line_1 = Line()\n",
    "    line_1.use_theme( \"dark\")\n",
    "    line_1.add(\"分笔\", \n",
    "               stock_df_bi['date'].tolist(), \n",
    "               stock_df_bi['chan_price'].tolist(),\n",
    "               line_color = 'yellow', \n",
    "               is_datazoom_show=True,\n",
    "               datazoom_type=\"both\",\n",
    "               xaxis_interval=10,\n",
    "               xaxis_rotate=30)\n",
    "    overlap.add(line_1)\n",
    "    \n",
    "    if stock_df_xd is not None:\n",
    "        line_2 = Line()\n",
    "        line_2.use_theme( \"dark\")\n",
    "        line_2.add(\"分段\", \n",
    "                   stock_df_xd['date'].tolist(), \n",
    "                   stock_df_xd['chan_price'].tolist(), \n",
    "                   line_color = 'blue',\n",
    "                   mark_point_symbol=\"arrow\", \n",
    "                   is_datazoom_show=True,\n",
    "                   datazoom_type=\"both\",\n",
    "                   xaxis_interval=10,\n",
    "                   xaxis_rotate=30)    \n",
    "        overlap.add(line_2)\n",
    "        \n",
    "    overlap.render(\"{0}@{1}.html\".format(stock, end_time))   \n",
    "    \n",
    "from jqdata import * \n",
    "stock = '300058.XSHE'\n",
    "end_time= pd.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "stock_df=get_bars(stock, \n",
    "                   count=1000, \n",
    "                   end_dt=end_time, \n",
    "                   unit='1d',\n",
    "                   fields= ['date', 'open',  'high', 'low','close'],\n",
    "                   fq_ref_date = datetime.datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\"),\n",
    "                   df=False)\n",
    "\n",
    "kc = KBarChan(stock_df, isdebug=False)\n",
    "stock_df_fenduan = kc.getFenDuan()\n",
    "\n",
    "draw_chan(stock, stock_df_fenduan, stock_df, kc, end_time) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "MarkDown菜单",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
