# é£é™©åŠå…è´£æç¤ºï¼šè¯¥ç­–ç•¥ç”±èšå®½ç”¨æˆ·åœ¨èšå®½ç¤¾åŒºåˆ†äº«ï¼Œä»…ä¾›å­¦ä¹ äº¤æµä½¿ç”¨ã€‚
# åŸæ–‡ä¸€èˆ¬åŒ…å«ç­–ç•¥è¯´æ˜ï¼Œå¦‚æœ‰ç–‘é—®è¯·åˆ°åŸæ–‡å’Œä½œè€…äº¤æµè®¨è®ºã€‚
# åŸæ–‡ç½‘å€ï¼šhttps://www.joinquant.com/post/33881
# æ ‡é¢˜ï¼šã€åˆ†äº«ã€‘åˆ¸å•†é‡‘è‚¡ç»„åˆå¢å¼º
# ä½œè€…ï¼šHugo2046
# å›æµ‹éœ€è¦é…åˆç ”ç©¶ä¸­çš„æœ¬åœ°æ•°æ®

'''
Author: Hugo
Date: 2021-05-19 10:38:22
LastEditTime: 2021-06-24 14:45:25
LastEditors: Hugo
Description: åˆ¸å•†é‡‘è‚¡ç­–ç•¥

æ¯æœˆåˆï¼ˆç¬¬2ä¸ªäº¤æ˜“æ—¥ï¼‰è·å–åˆ¸å•†çš„é‡‘è‚¡æ•°æ®ï¼ˆæ­¤éƒ¨åˆ†æ•°æ®æ¥æºäºæ‰‹åŠ¨æ•´ç†çš„æ–‡ä»¶gold_stock_20210609.csvï¼‰å…¶æ•°æ®ç»“æ„
è§read_gold_stockï¼›
æ¯å‘¨ä½¿ç”¨åŠ¨é‡å› å­å¯¹æœˆåˆè·å–çš„é‡‘è‚¡è¿›è¡Œç­›é€‰ï¼Œè·å–å¾—åˆ†å‰Nçš„è‚¡ç¥¨(g.handle_numè¿›è¡Œæ§åˆ¶)ï¼›
'''

from jqdata import *
from jqfactor import (Factor,calc_factors)
# èšå®½çš„ç»„åˆä¼˜åŒ–
from jqlib.optimizer import (portfolio_optimizer,
                             MaxProfit,
                             MaxSharpeRatio,
                             RiskParity,
                             MinVariance,
                             WeightConstraint, Bound)

import functools
from dateutil.parser import parse

from scipy import stats
from scipy import optimize
import statsmodels.api as sm
from sklearn.covariance import ledoit_wolf

import numpy as np
import pandas as pd
import datetime as dt
from typing import (List, Tuple, Union,Callable)
from six import BytesIO  # æ–‡ä»¶è¯»å–


def initialize(context):

    set_params()
    set_variables()
    set_backtest()
    g.in_week = 5  # å‘¨å†…ç¬¬äº”ä¸ªäº¤æ˜“æ—¥

    # æ¯æœˆçš„ç¬¬äº”ä¸ªäº¤æ˜“æ—¥è°ƒä»“
    run_monthly(get_target_securities, 2, 'open',
                reference_security='000300.XSHG')
    run_weekly(trade_func, g.in_week, 'open', reference_security='000300.XSHG')

# é…ç½®åŸºç¡€å‚æ•°


def set_params():

    # æ˜¯å¦ä½¿ç”¨å› å­è¿›è¡Œè¾…åŠ©
    # ä¸ºTrueä½¿ç”¨åŠ¨é‡å› å­,Falseä½¿ç”¨åˆ¸å•†æ¨èç‡
    g.use_factor = True

    # è®¾ç½®æŒä»“
    g.handle_num = 15

    # è·å–é‡‘è‚¡æ•°æ®
    read_gold_stock()
    
    # æ˜¯å¦ç»„åˆä¼˜åŒ–
    # å¯é€‰é¡¹:MaxSharpeRatioï¼ŒMaxProfit,MinVariance,RiskParity
    # Falseä¸ºä¸ç»„åˆä¼˜åŒ–
    g.optimizer_mod = 'MaxProfit'  # 'MaxSharpeRatio'

# åŸºç¡€å˜é‡


def set_variables():

    g.base_target: pd.DataFrame = None  # å‚¨å­˜å½“æœˆé‡‘è‚¡

# å›æµ‹è®¾ç½®


def set_backtest():

    set_option("avoid_future_data", True)  # é¿å…æ•°æ®
    set_option("use_real_price", True)  # çœŸå®ä»·æ ¼äº¤æ˜“
    set_option('order_volume_ratio', 1)  # æ ¹æ®å®é™…è¡Œæƒ…é™åˆ¶æ¯ä¸ªè®¢å•çš„æˆäº¤é‡
    set_benchmark('000300.XSHG')  # è®¾ç½®åŸºå‡†
    #log.set_level("order", "debuge")
    log.set_level('order', 'error')


# æ¯æ—¥ç›˜å‰è¿è¡Œ è®¾ç½®ä¸åŒåŒºé—´æ‰‹ç»­è´¹
def before_trading_start(context):

    # æ‰‹ç»­è´¹è®¾ç½®
    # å°†æ»‘ç‚¹è®¾ç½®ä¸º0.002
    set_slippage(FixedSlippage(0.002))

    # æ ¹æ®ä¸åŒçš„æ—¶é—´æ®µè®¾ç½®æ‰‹ç»­è´¹
    dt = context.current_dt

    if dt > datetime.datetime(2013, 1, 1):
        set_commission(PerTrade(buy_cost=0.0003, sell_cost=0.0013, min_cost=5))

    elif dt > datetime.datetime(2011, 1, 1):
        set_commission(PerTrade(buy_cost=0.001, sell_cost=0.002, min_cost=5))

    elif dt > datetime.datetime(2009, 1, 1):
        set_commission(PerTrade(buy_cost=0.002, sell_cost=0.003, min_cost=5))

    else:
        set_commission(PerTrade(buy_cost=0.003, sell_cost=0.004, min_cost=5))


'''è¯»å–é‡‘è‚¡çš„å‚¨å­˜æ–‡ä»¶'''


def read_gold_stock() -> None:

    # è¯»å–å‚¨å­˜é‡‘è‚¡çš„æ–‡ä»¶ èµ·å§‹æ—¥æœŸ2019å¹´7æœˆ
    '''
    æ–‡ä»¶ç»“æ„ï¼š
        ----------------------------------------------
        |æ‰€å±æ—¥æœŸ|æ¨èæœºæ„|è‚¡ç¥¨åç§°|æ‰€å±è¡Œä¸š|è‚¡ç¥¨ä»£ç  |
        ----------------------------------------------
        |2019/7/1|å®‰ä¿¡è¯åˆ¸|ç§‘å¤§è®¯é£|  è®¡ç®—æœº|002230.SZ|
        -----------------------------------------------
    '''
    g.gold_stock_frame = pd.read_csv(BytesIO(read_file('gold_stock_20210609.csv')),
                                     index_col='æ‰€å±æ—¥æœŸ', parse_dates=['æ‰€å±æ—¥æœŸ'])

    # è¿‡æ»¤æ¸¯è‚¡
    g.gold_stock_frame = g.gold_stock_frame[(
        g.gold_stock_frame['è‚¡ç¥¨ä»£ç '].str[-2:] != 'HK')]
    # è‚¡ç¥¨ä»£ç è½¬ä¸ºèšå®½çš„ä»£ç æ ¼å¼
    g.gold_stock_frame['è‚¡ç¥¨ä»£ç '] = g.gold_stock_frame['è‚¡ç¥¨ä»£ç '].apply(
        normalize_code)
    # å°†ç´¢å¼•è½¬ä¸ºå¹´-æœˆå½¢å¼
    g.gold_stock_frame.index = g.gold_stock_frame.index.strftime('%Y-%m')


'''å…¶ä»–'''

@functools.lru_cache()
def get_weekofyear_date() -> pd.DataFrame:
    '''
    è·å– å‘¨åº¦äº¤æ˜“æ—¥æœŸ
    ------
        return index=date columns date num_week:å‘¨åº¦ä¸­çš„ç¬¬Nä¸ªäº¤æ˜“æ—¥
    '''
    idx = get_all_trade_days()
    days = pd.DataFrame(idx, index=pd.DatetimeIndex(idx), columns=['date'])
    days['num_week'] = days.groupby([
        days.index.year, days.index.weekofyear
    ])['date'].transform(lambda x: range(1,
                                         len(x) + 1))

    return days

def get_num_weekly_trade_days(days: pd.DataFrame, N: int) -> pd.Series:
    '''
    è·å–å‘¨åº¦çš„ç¬¬Nä¸ªäº¤æ˜“æ—¥
    ------
    è¾“å…¥å‚æ•°:
        days:index=date columns date num_week
        N:ç¬¬Nä¸ªäº¤æ˜“æ—¥
    ------
    return pd.DataFrame
           index-datetime.datetime columns-datetime.date
    '''

    cond = days.groupby([days.index.year, days.index.weekofyear
                         ])['num_week'].apply(lambda x: x == min(len(x), N))
    target = days[cond]

    return target.drop(columns=['num_week'])
    
def get_past_weekly_days(watch_date: str, weekly_n: int, count: int) -> list:
    '''
    æŸ¥è¯¢è¿‡å»NæœŸçš„å‘¨åº¦èŠ‚ç‚¹æ—¥æœŸ
    ------
    è¾“å…¥å‚æ•°:
        watch_date:è§‚å¯ŸæœŸ
        weekly_n:å‘¨å†…ç¬¬Nä¸ªäº¤æ˜“æ—¥
        count:è·å–å‰NæœŸ
    -----
        return list-datetime.date
    '''

    if isinstance(watch_date, str):
        watch_date = parse(watch_date)

    days = get_weekofyear_date()
    weekly = get_num_weekly_trade_days(days.loc[:watch_date], weekly_n)

    return weekly['date'].iloc[-count - 1:].values.tolist()
    
def get_next_returns(factor_df: pd.DataFrame,
                     last_date: str = None) -> pd.DataFrame:
    '''
    è·å–ä¸‹æœŸæ”¶ç›Šç‡
    ------
    è¾“å…¥:
        factor_df:MuliIndex-level0-datetime.date level1-code columns - factors
        last_date:æœ€åä¸€æœŸæ—¶é—´
    '''
    if last_date:
        days = pd.to_datetime(
            factor_df.index.get_level_values('date').unique().tolist() +
            [last_date])
    else:
        days = pd.to_datetime(
            factor_df.index.get_level_values('date').unique().tolist())

    dic = {}
    for s, e in zip(days[:-1], days[1:]):

        stocks = factor_df.loc[s.date()].index.get_level_values(
            'code').unique().tolist()

        a = get_price(stocks, end_date=s, count=1, fields='close',
                      panel=False).set_index('code')['close']

        b = get_price(stocks, end_date=e, count=1, fields='close',
                      panel=False).set_index('code')['close']

        dic[s] = b / a - 1

    df = pd.concat(dic).to_frame('next_ret')

    df.index.names = ['date', 'code']
    return df
    
def prepare_data(securities: list, watch_date: str, N: int,
                 count: int) -> Tuple[pd.DataFrame, pd.DataFrame]:
    '''
    è·å–å½“æœŸè‚¡ç¥¨æ±  è¿‡å»NæœŸçš„å› å­å€¼åŠæœªæ¥æœŸæ”¶ç›Šç‡
    TæœŸæ²¡æœ‰æœªæ¥æœŸæ”¶ç›Š,ä»…T-1è‡³T-NæœŸæœ‰
    ------
    è¾“å…¥å‚æ•°:
        securities:è‚¡ç¥¨åˆ—è¡¨
        watch_date:è§‚å¯ŸæœŸ
        N:å‘¨åº¦äº¤æ˜“æ—¥
        count:è¿‡å»NæœŸ
    ------
    return 
        factor_df, next_ret
    '''

    periods = get_past_weekly_days(watch_date, N, count)

    f_dict = {}

    for trade in periods:

        f_dict[trade] = get_momentum_factor(securities, trade)

    f_df = pd.concat(f_dict, names=['date', 'code'])

    next_ret = get_next_returns(f_df)

    return f_df, next_ret


def composition_factors(securities:list,watchDt:str,in_week: int,window: int) -> pd.DataFrame:
    '''
    è·å–å›æµ‹èŒƒå›´å†…çš„å› å­åˆæˆå€¼
    ------
    è¾“å…¥å‚æ•°
        securities:é‡‘è‚¡æ•°æ®è¡¨
        in_week:æ¯å‘¨çš„æœ€åä¸€æ—¥è¿›è¡Œè°ƒä»“
        num_trade:æ¯æœˆçš„ç¬¬Nä¸ªäº¤æ˜“æ—¥è·å–åˆ°é‡‘è‚¡å¹¶äº¤æ˜“
        window:å›çœ‹çª—å£æœŸä¸º12å‘¨
    
    '''
   
    # è·å–Tè‡³T-NæœŸå› å­å€¼
    f_df, next_ret = prepare_data(securities, watchDt, in_week, window)

    # è°ƒç”¨å› å­åˆæˆç±»
    fw = FactorWeight(f_df, next_ret)

    # è·å–ä¸åŒå› å­åˆæˆçš„å€¼
    method_dic = {
        'ç­‰æƒæ³•': fw.fac_eqwt(),
        'å†å²å› å­æ”¶ç›Šç‡åŠ æƒæ³•': fw.fac_ret_half(False),
        'å†å²å› å­æ”¶ç›Šç‡åŠè¡°åŠ æƒæ³•': fw.fac_ret_half(True),
        'å†å²å› å­ICåŠ æƒæ³•': fw.fac_ic_half(2),
        'æœ€å¤§åŒ–IC_IRåŠ æƒæ³•': fw.fac_maxicir_samp(),
        'æœ€å¤§åŒ– IC_IR åŠ æƒæ³•(Ledoit)': fw.fac_maxicir(),
        'æœ€å¤§åŒ–IC_IRåŠ æƒæ³•': fw.fac_maxic()
    }

    df = pd.concat((ser for ser in method_dic.values()), axis=1)
    df.columns = list(method_dic.keys())

    
    return df
    
def time2str(watch_date: dt.datetime, fmt='%Y-%m-%d') -> str:
    '''æ—¥æœŸè½¬æ–‡æœ¬'''
    if isinstance(watch_date, (dt.datetime, dt.date)):
        return watch_date.strftime(fmt)
    else:
        return time2str(parse(watch_date))



'''é‡‘è‚¡ç­›é€‰æŒ‡æ ‡'''

# è®¡ç®—åˆ¸å•†æ¨èç‡


def get_net_promoter_score(target_df: pd.DataFrame) -> pd.Series:
    '''è®¡ç®—åˆ¸å•†æ¨èç‡'''

    return target_df.groupby('è‚¡ç¥¨ä»£ç ')['æ¨èæœºæ„'].count() / len(target_df['æ¨èæœºæ„'].unique())


'''å› å­æ„é€ '''

# å› å­åˆæˆæ–¹æ³•
class FactorWeight(object):
    '''
    å‚è€ƒ:ã€Š20190104-åæ³°è¯åˆ¸-å› å­åˆæˆæ–¹æ³•å®è¯åˆ†æã€‹
    -------------
    ä¼ å…¥TæœŸå› å­åŠæ”¶ç›Šæ•°æ® ä½¿ç”¨T-1è‡³T-NæœŸæ•°æ®è®¡ç®—å› å­çš„åˆæˆæƒé‡
    
    ç°æœ‰æ–¹æ³•ï¼š
    1. fac_eqwt ç­‰æƒæ³•
    2. fac_ret_half å†å²å› å­æ”¶ç›Šç‡ï¼ˆåŠè¡°ï¼‰åŠ æƒæ³•
    3. fac_ic_half å†å²å› å­ ICï¼ˆåŠè¡°ï¼‰åŠ æƒæ³•
    4. fac_maxicir_samp æœ€å¤§åŒ– IC_IR åŠ æƒæ³• æ ·æœ¬åæ–¹å·®
       fac_maxicir  Ledoitå‹ç¼©ä¼°è®¡æ–¹æ³•è®¡ç®—åæ–¹å·®
    5. fac_maxic æœ€å¤§åŒ–ICåŠ æƒæ³• Ledoitå‹ç¼©ä¼°è®¡æ–¹æ³•è®¡ç®—åæ–¹å·®
    ------
    è¾“å…¥å‚æ•°:
        factor:MuliIndex level0ä¸ºdate,level1ä¸ºcode,columnsä¸ºå› å­å€¼
            -----------------------------------
                date    |    asset   |
            -----------------------------------
                        |   AAPL     |   0.5
                        -----------------------
                        |   BA       |  -1.1
                        -----------------------
            2014-01-01  |   CMG      |   1.7
                        -----------------------
                        |   DAL      |  -0.1
                        -----------------------
                        |   LULU     |   2.7
                        -----------------------

        next_returnsï¼šä¸‹æœŸæ”¶ç›Šç‡,ç»“æ„ä¸factorç›¸åŒ
    '''
    def __init__(self, factor: pd.DataFrame,
                 next_returns: pd.DataFrame) -> None:

        self.factor, self.next_returns = factor.align(next_returns,
                                                      join='left',
                                                      axis=0)

        # æ•°æ®æ ¼å¼æ•´ç†
        self.factor.index.names = ['date', 'code']
        self.next_returns.index.names = ['date', 'code']

        self._split_data()  # æ‹†åˆ†æ•°æ®
        self.IC = self._calc_ic(self.past_factor,
                                self.past_returns)  # è®¡ç®—Rank IC

    def _split_data(self) -> None:
        '''
        å°†åŸæœ‰æ•°æ®æ‹†åˆ†ä¸ºå½“æœŸ(TæœŸ)ä¸å‰åºT-1è‡³T-NæœŸ
        '''

        self.last_day = self.factor.index.get_level_values(
            'date').max()  # è·å–å½“æœŸæ—¥æœŸ
        self.last_factor = self.factor.loc[self.last_day]  # è·å–å½“æœŸå› å­

        # å‰æœŸæ•°æ®
        self.past_factor = (
            self.factor.unstack().sort_index().iloc[:-1].stack())

        self.past_returns = (
            self.next_returns.unstack().sort_index().iloc[:-1].stack())

        self.past_returns.name = 'next_ret'

    def fac_eqwt(self) -> pd.Series:
        '''ç­‰æƒåˆæˆ'''

        return self.last_factor.mean(axis=1)

    def fac_ret_half(self, halflife: bool = True) -> pd.Series:
        '''
        å†å²å› å­æ”¶ç›Šç‡(åŠè¡°)åŠ æƒæ³•

        æœ€è¿‘ä¸€æ®µæ—¶æœŸå†…å†å²å› å­æ”¶ç›Šç‡çš„ç®—æœ¯å¹³å‡å€¼ï¼ˆæˆ–åŠè¡°æƒé‡ä¸‹çš„åŠ æƒå¹³å‡å€¼ï¼‰ä½œä¸ºæƒé‡è¿›è¡Œç›¸åŠ 
        å¦‚æœè¿™å…­ä¸ªå› å­çš„å†å²å› å­æ”¶ç›Šç‡å‡å€¼åˆ†åˆ«æ˜¯ 1ã€2ã€3ã€4ã€5ã€6ï¼Œåˆ™æ¯ä¸ªå› å­çš„æƒé‡åˆ†åˆ«ä¸ºï¼š
        1/ï¼ˆ1+2+3+4+5+6ï¼‰= 1/21ã€2/ï¼ˆ1+2+3+4+5+6ï¼‰= 2/21ã€3/21ã€4/21ã€5/21ã€
        6/21ï¼Œå³ä¸º 4.76%ã€9.52%ã€14.29%ã€19.05%ã€23.81%ã€28.57%
        ---------
            halflife:é»˜è®¤ä¸ºTrueä½¿ç”¨åŠè¡°æœŸåŠ æƒ,Falseä¸ºç­‰æƒ 
        '''

        # è·å–å› å­æ”¶ç›Šç‡
        factor_returns = self._get_factor_return(self.past_factor,
                                                 self.past_returns)

        ret_mean = factor_returns.mean()

        # ä½¿ç”¨åŠè¡°æœŸ
        if halflife:

            self.weight = ret_mean / ret_mean.sum()

        else:
            # æœªä½¿ç”¨åŠè¡°æœŸ
            self.weight = ret_mean

        # å› å­åˆæˆ
        return (self.last_factor.mul(self.weight).sum(axis=1))

    def fac_ic_half(self, halflife: int = None) -> pd.Series:
        '''
        å†å²å› å­ ICï¼ˆåŠè¡°ï¼‰åŠ æƒæ³•

        æŒ‰ç…§æœ€è¿‘ä¸€æ®µæ—¶æœŸå†…å†å²RankICçš„ç®—æœ¯å¹³å‡å€¼ï¼ˆæˆ–åŠè¡°æƒé‡ä¸‹çš„åŠ æƒå¹³å‡å€¼ï¼‰ä½œä¸ºæƒé‡è¿›è¡Œç›¸åŠ ï¼Œ
        å¾—åˆ°æ–°çš„åˆæˆåå› å­
        ------
        è¾“å…¥å‚æ•°:
            halflife:åŠè¡°æœŸ,1,2,4ç­‰ é€šå¸¸ä½¿ç”¨2
        '''

        if halflife:

            # æ„é€ åŠè¡°æœŸ
            ic_weight = self._build_halflife_wight(self.IC.shape[0], halflife)

            self.weight = self.IC.apply(
                lambda x: np.average(x, weights=ic_weight))

            return (self.last_factor.mul(self.weight).sum(axis=1))

        else:

            self.weight = self.IC.mean()

            return (self.last_factor.mul(self.weight).sum(axis=1))

    def fac_maxicir_samp(self,
                         explicit_solutions: bool = False,
                         fill_Neg: str = 'normal') -> pd.Series:
        '''
        æœ€å¤§åŒ– IC_IR åŠ æƒæ³•

        ä»¥å†å²ä¸€æ®µæ—¶é—´çš„å¤åˆå› å­å¹³å‡ICå€¼ä½œä¸ºå¯¹å¤åˆå› å­ä¸‹ä¸€æœŸICå€¼çš„ä¼°è®¡ï¼Œ
        ä»¥å†å² IC å€¼çš„åæ–¹å·®çŸ©é˜µä½œä¸ºå¯¹å¤åˆå› å­ä¸‹ä¸€æœŸæ³¢åŠ¨ç‡çš„ä¼°è®¡
        ------
        è¾“å…¥å‚æ•°ï¼š
            explicit_solutions ä¸ºTrueæ—¶ä½¿ç”¨æ˜¾ç¤ºè§£,Falseä½¿ç”¨çº¦æŸè§£
            fill_Neg:å½“ä½¿ç”¨æ˜¾ç¤ºè§£æ—¶å¯¹å°äº0éƒ¨åˆ†çš„å¤„ç†
                     normal:ä½¿ç”¨0å¡«å……
                     mean:ä½¿ç”¨ICå‡å€¼å¡«å……
        '''

        # æ˜¾ç¤ºè§£
        if explicit_solutions:

            self.weight = self._explicit_solutions_icir(self.IC, fill_Neg)

        else:

            # çº¦æŸè§£
            self.weight = self._opt_icir(self.IC, fill_Neg,
                                         self._target_func_samp)

        return (self.last_factor.mul(self.weight).sum(axis=1))

    def fac_maxicir(self, fill_Neg: str = 'normal') -> pd.Series:

        # çº¦æŸè§£
        self.weight = self._opt_icir(self.IC, fill_Neg, self._target_func)

        return (self.last_factor.mul(self.weight).sum(axis=1))

    def fac_maxic(self) -> pd.Series:
        '''
        æœ€å¤§åŒ– IC åŠ æƒæ³•
        
        $max IC = \frac{w.T * IC}{\sqrt{w.T * V *w}}
        
        ğ‘‰æ˜¯å½“å‰æˆªé¢æœŸå› å­å€¼çš„ç›¸å…³ç³»æ•°çŸ©é˜µ(ç”±äºå› å­å‡è¿›è¡Œè¿‡æ ‡å‡†åŒ–,è‡ªèº«æ–¹å·®ä¸º1,å› æ­¤ç›¸å…³ç³»æ•°çŸ©é˜µäº¦æ˜¯åæ–¹å·®é˜µ)
        åæ–¹å·®ä½¿ç”¨å‹ç¼©åæ–¹å·®çŸ©é˜µä¼°è®¡æ–¹å¼
        
        ä½¿ç”¨çº¦æŸè§£
        '''

        z_score = (self.past_factor.fillna(0) -
                   self.past_factor.mean()) / self.past_factor.std()

        V = ledoit_wolf(z_score)[0]
        mean_ic = self.IC.mean()

        size = len(mean_ic)
        np.random.seed(42)

        # s.t w >= 0
        bounds = tuple((0, None) for _ in range(size))

        res = optimize.minimize(
            fun=lambda w: -np.divide(w.T @ mean_ic, np.sqrt(w @ V @ w.T)),
            x0=np.random.randn(size),
            bounds=bounds)

        if res['success']:

            self.weight = pd.Series(res['x'], index=mean_ic.index.tolist())

        else:

            logging.warning('ä¼˜åŒ–å¤±è´¥')

        return (self.last_factor.mul(self.weight).sum(axis=1))

    @staticmethod
    def _calc_ic(factor: pd.DataFrame, next_ret: pd.Series) -> pd.Series:
        '''è®¡ç®—Rank IC'''
        def scr_ic(group: pd.DataFrame) -> pd.DataFrame:

            f_cols = [col for col in group.columns if col != 'next_ret']

            return pd.Series({
                col: stats.spearmanr(group[col], group['next_ret'])[0]
                for col in f_cols
            })

        df = pd.concat((factor, next_ret), axis=1)

        return df.fillna(0).groupby(level='date').apply(scr_ic)

    @staticmethod
    def _build_halflife_wight(T: int, H: int) -> np.array:
        '''
        ç”ŸæˆåŠè¡°æœŸæƒé‡

        $w_t = 2^{\frac{t-T-1}{H}}(t=1,2,...,T)$
        å®é™…éœ€è¦å½’ä¸€åŒ–,w^{'}_{t}=\frac{w_t}{\sumw_t}
        ------

        è¾“å…¥å‚æ•°:
            T:æœŸæ•°
            H:åŠè¡°æœŸå‚æ•°
        '''

        periods = np.arange(1, T + 1)

        return np.power(2, np.divide(periods - T - 1, H)) * 0.5

    @staticmethod
    def _get_factor_return(factor: pd.DataFrame,
                           next_returns: pd.Series) -> pd.DataFrame:
        '''
        è·å–å› å­æ”¶ç›Š
        '''

        df = pd.concat((factor, next_returns), axis=1).fillna(0)
        f_col = [col for col in df.columns if col != 'next_ret']

        def ols(endog: pd.Series, exog: pd.DataFrame) -> pd.DataFrame:
            '''ä½¿ç”¨wlså›å½’è·å–å› å­æ”¶ç›Š'''

            X = sm.add_constant(exog)
            model = sm.OLS(endog, X)
            results = model.fit()

            return results.params

        factor_ret = df.groupby(
            level='date').apply(lambda x: ols(x['next_ret'], x[f_col]))

        return factor_ret.drop(columns='const')

    @staticmethod
    def _explicit_solutions_icir(ic: pd.DataFrame, fill_Neg: str) -> pd.Series:
        '''
        è®¡ç®—ic irçš„æ˜¾ç¤ºè§£
        ------
        è¾“å…¥å‚æ•°:
            ic:è¿‡å»ä¸€æ®µæ—¶é—´çš„icæ•°æ®
            window:è®¡ç®—icå‡å€¼çš„æ»šåŠ¨æœŸ

        '''
        mean_ic = ic.mean()
        std_ic = ic.std()

        ic_ir = mean_ic / std_ic

        if fill_Neg == 'normal':

            ic_ir = np.where(ic_ir < 0, 0, ic_ir)

        elif fill_Neg == 'mean':

            ic_ir = np.where(ic_ir < 0, mean_ic, ic_ir)

        return ic_ir

    def _opt_icir(self, ic: pd.DataFrame, fill_Neg: str,
                  target_func: Callable) -> pd.Series:
        '''
        çº¦æŸæ¡ä»¶ä¸‹ä¼˜åŒ–å¤±è´¥æ—¶è°ƒç”¨ï¼Œ_explicit_solutions_icirå‡½æ•°
        ------
        è¾“å…¥å‚æ•°:
            mean_ic:index-å› å­å value-å› å­åœ¨ä¸€æ®µæ—¶é—´å†…å¾—icå‡å€¼

        '''

        size = ic.shape[1]
        np.random.seed(42)
        # s.t w >= 0
        bounds = tuple((0, None) for _ in range(size))

        res = optimize.minimize(fun=target_func,
                                x0=np.random.randn(size),
                                args=ic,
                                bounds=bounds)

        if res['success']:

            return pd.Series(res['x'], index=ic.columns.tolist())

        else:

            logging.warning(f'è®¡ç®—å¤±è´¥')

            return self._explicit_solutions_icir(ic, fill_Neg)

    @staticmethod
    def _target_func_samp(w: np.array, ic: pd.DataFrame) -> float:
        '''
        ä½¿ç”¨æ ·æœ¬åæ–¹å·®
        æœ€å¤§åŒ–IC IRçš„ç›®æ ‡å‡½æ•°
        ------
        è¾“å…¥å‚æ•°:
            w:å› å­åˆæˆçš„æƒé‡
            ic:ICå‡å€¼å‘é‡ æ•°æ®ä¸ºå› å­åœ¨è¿‡å»ä¸€æ®µæ—¶é—´çš„ICå‡å€¼
        '''

        mean_ic = ic.mean()

        return -np.divide(w.T @ mean_ic, np.sqrt(w @ ic.cov() @ w.T))

    @staticmethod
    def _target_func(w: np.array, ic: pd.DataFrame) -> float:
        '''
        ä½¿ç”¨ledoitåæ–¹å·®
        æœ€å¤§åŒ–IC IRçš„ç›®æ ‡å‡½æ•°
        ------
        è¾“å…¥å‚æ•°:
            w:å› å­åˆæˆçš„æƒé‡
            ic:ICå‡å€¼å‘é‡ æ•°æ®ä¸ºå› å­åœ¨è¿‡å»ä¸€æ®µæ—¶é—´çš„ICå‡å€¼
        '''
        mean_ic = ic.mean()

        return -np.divide(w.T @ mean_ic, np.sqrt(w @ ledoit_wolf(ic)[0] @ w.T))
        
        
# æŒ¯å¹…å› å­


class AF_factor(object):

    '''
    lambä¸ºåˆ‡åˆ†å˜é‡
    groupä¸ºé«˜ä½åˆ†ç»„high,lowä¸¤ä¸ªå‚æ•°
    '''

    def __init__(self, securities: Union[str, list], watch_date: str, N: int) -> None:

        self.securities = securities

        self.watch_date = watch_date

        self._N = N

        self.max_window = N + 2

    def get_data(self):
        '''æ•°æ®è·å–'''

        data = get_price(self.securities,
                         end_date=self.watch_date,
                         count=self.max_window,
                         fields=['close', 'high', 'low', 'paused'], panel=False)

        self.data = data.pivot(index='time', columns='code')

    def calc(self, lamb: float, group: str) -> pd.Series:
        '''å› å­è®¡ç®—'''
        self.lamb = round(lamb, 2)
        self.group = group

        af_df = self._calc_af()
        af_df = af_df.iloc[-self._N:]

        cond1 = self._q_split()
        cond1 = cond1.iloc[-self._N:]

        cond2 = self._get_paused()
        cond2 = cond2.iloc[-self._N:]

        cond = cond1 * cond2

        ser = (af_df * cond).mean()
        ser.name = self.name
        return ser

    def _q_split(self) -> pd.DataFrame:
        '''åˆ†å‰²'''
        close = self.data['close']

        cond = close.rank(pct=True) >= self.lamb

        if self.group == 'high':

            return close.rank(pct=True, ascending=False) <= self.lamb

        elif self.group == 'low':

            return close.rank(pct=True, ascending=True) <= self.lamb

        else:
            raise ValueError('groupå‚æ•°ä»…èƒ½ä¸ºhigh,low.')

    def _calc_af(self) -> pd.DataFrame:
        '''è®¡ç®—æŒ¯å¹…'''
        return self.data['high'] / self.data['low'] - 1

    def _get_paused(self) -> pd.DataFrame:
        '''ä¸€å­—è·Œåœåä¸€æ—¥æ ‡è®°ä¸ºFalse'''
        close_df = self.data['close']
        high_df = self.data['high']
        low_df = self.data['low']
        paused = self.data['paused']  # åœç‰Œ

        # è·Œåœ
        cond1 = (close_df / close_df.shift(1) - 1) < -0.09
        # ä¸€å­—
        cond2 = (high_df == low_df)

        res = (cond1 & cond2)
        res = (paused + res).astype(bool)

        return (~res).shift(1)

    def v_factor(self, lamb: float = 0.5) -> pd.Series:

        return self.calc(lamb, 'high') - self.calc(lamb, 'low')

    @property
    def name(self) -> str:

        return f'AF_{round(self.lamb,2)}_{self.group}'

# èªæ˜é’±å› å­


class Q_factor(object):

    def __init__(self, securities: Union[str, list], watch_date: str, N: int = 10, frequency: str = '30m', mod: str = 'normal') -> None:

        self.securities = securities
        self.watch_date = watch_date
        self.frequency = frequency
        self.N = N
        self._get_count()
        self.mod = mod  # normalä¼ ç»Ÿ lnå¯¹æ•°

    def get_data(self):

        self.data = get_price(self.securities,
                              end_date=self.watch_date,
                              count=self.minute_count * self.N, frequency='30m',
                              fields=['close', 'volume', 'open'],
                              panel=False)

    def _get_count(self):
        '''è®¡ç®—ä¸€æ—¥éœ€è¦å¤šå°‘ä¸ªå‘¨æœŸ'''
        ALL_DAY = 240  # ä¸€ä¸ªå®Œæ•´äº¤æ˜“æ—¥åˆ†é’Ÿæ•°

        if self.frequency[-1] != 'm':

            raise ValueError('frequencyå‚æ•°å¿…é¡»æ˜¯X minute(Xå¿…é¡»æ˜¯æ•´æ•°)')

        self.minute_count = ALL_DAY / int(self.frequency.replace('m', ''))

    def calc(self, beta: float = -0.5) -> pd.Series:

        self.beta = round(beta, 2)
        # æ–‡ç« è²Œä¼¼æ²¡è¯´æ¶¨åœè‚¡çš„å¤„ç†...å¦‚æœæ¶¨åœå¯¹æ­¤å› å­çš„å½±å“åº”è¯¥å¾ˆå¤§
        data = (self.data.query('volume != 0')
                         .pivot(index='time', columns='code'))

        close_df = data['close']
        vol_df = data['volume']
        open_df = data['open']

        ret_df = close_df / open_df - 1
        abs_ret = ret_df.abs()

        if self.mod == 'normal':

            # St = |Rt|/âˆšVtï¼Œå…¶ä¸­ğ‘…ğ‘¡ä¸ºç¬¬ t åˆ†é’Ÿæ¶¨è·Œå¹…ï¼Œğ‘‰ğ‘¡ä¸ºç¬¬ t åˆ†é’Ÿæˆäº¤é‡
            S = abs_ret / vol_df.pow(beta)

        else:

            # åˆ†é’Ÿæ¶¨è·Œå¹…ç»å¯¹å€¼é™¤ä»¥åˆ†é’Ÿæˆäº¤é‡å¯¹æ•°å€¼
            S = abs_ret / np.log(vol_df)

        # é™åºæ’åˆ—ã€ä»å¤§åˆ°å°æ’åºã€‘
        S_rank = S.rank(ascending=False)

        concat_df = pd.concat(
            (S_rank.stack(), vol_df.stack(), close_df.stack()), axis=1, sort=True)
        concat_df.columns = ['rank', 'vol', 'close']

        ser = concat_df.groupby(level='code').apply(self.calc_Q)
        ser.name = self.name
        return ser

    # @staticmethod
    def calc_Q(self, df: pd.DataFrame) -> float:

        def vwap(df: pd.DataFrame) -> float:
            '''è®¡ç®—vwap'''

            try:

                v = np.average(df['close'], weights=df['vol'])

            except ZeroDivisionError:

                print(self.watch_date)
                print(df)
                print(sort_df['vol'])
                raise ValueError('ZeroDivisionError')

            return v

        def _add_flag(sort_df: pd.DataFrame) -> pd.Series:
            '''
            æ ‡è®°å°†åˆ†é’Ÿæ•°æ®æŒ‰ç…§æŒ‡æ ‡Stä»å¤§åˆ°å°è¿›è¡Œæ’åºï¼Œ
            å–æˆäº¤é‡ç´¯ç§¯å æ¯”å‰20%çš„åˆ†é’Ÿ
            '''

            cum_df = sort_df['vol'].cumsum() / sort_df['vol'].sum()

            cond = (cum_df <= 0.2)

            if (sort_df[cond].empty) and (cum_df.iloc[0] > 0.2):

                return sort_df.iloc[:1, :]

            return sort_df[cond]

        # å°†åˆ†é’Ÿæ•°æ®æŒ‰ç…§æŒ‡æ ‡Stä»å¤§åˆ°å°è¿›è¡Œæ’åºï¼Œå–æˆäº¤é‡ç´¯ç§¯å æ¯”å‰20%çš„åˆ†é’Ÿ,è§†ä¸ºèªæ˜é’±äº¤æ˜“
        sort_df = (df.reset_index()
                     .set_index('rank')
                     .sort_index())

        smart_df = _add_flag(sort_df)
        # è®¡ç®—èªæ˜é’±äº¤æ˜“çš„æˆäº¤é‡åŠ æƒå¹³å‡ä»·VWAPsmart
        vwap_smart = vwap(smart_df)
        # è®¡ç®—æ‰€æœ‰äº¤æ˜“çš„æˆäº¤é‡åŠ æƒå¹³å‡ä»·VWAPall
        vwap_all_f = vwap(sort_df)

        return vwap_smart / vwap_all_f

    @property
    def name(self) -> str:

        return f'Q_{self.N}_{self.frequency}_{self.beta}'

# åŠ¨é‡å› å­


class RetN_momentum(object):

    def __init__(self, securities: Union[str, list], watch_date: str, max_window: int) -> None:

        self.securities = securities
        self.watch_date = watch_date
        self.max_window = max_window + 1

    def get_data(self) -> None:
        '''æ•°æ®è·å–'''
        data = get_price(self.securities, end_date=self.watch_date,
                         count=self.max_window, fields=['high', 'low', 'close'], panel=False)
        self.data = data.pivot(index='time', columns='code')

    def calc(self, mod: str, lamb: float, group: str = None) -> pd.Series:
        '''å› å­è®¡ç®—

        mod:ä¸ºè®¡ç®—æ–¹æ³•ï¼Œsortæ’åºåˆ†å‰²,qåˆ†ä½æ•°åˆ†å‰²,lambæŒ‰é˜ˆå€¼è¿›è¡Œåˆ†å‰²
        group:é«˜ä½åˆ†ç»„ high/low
        å½“modä¸ºsortæ—¶ lambåŠqæ— æ•ˆ
        '''
        self.mod = mod
        self.lamb = lamb

        mod_dic = {'sort': self._sort_split,
                   'q': self._lamb_quantile, 'lamb': self._lamb_split}

        af_df = self._get_AF(self.data).iloc[1:]
        pct_chg = self.data['close'].pct_change().iloc[1:]

        cond = mod_dic[self.mod](af_df=af_df, lamb=self.lamb)

        if self.mod == 'sort' and self.group == 'A':

            # ä½æŒ¯å¹…
            return (~cond * pct_chg).sum()

        elif self.mod == 'sort' and self.group == 'B':

            # é«˜æŒ¯å¹…
            return (cond * pct_chg).sum()

        elif self.mod == 'q':
            # qæ¨¡å¼ä¸‹
            return (cond * pct_chg).sum()

        elif self.mod == 'lamb':
            # lambæ¨¡å¼
            return (cond * pct_chg).sum()

    @staticmethod
    def _get_AF(data: pd.DataFrame) -> pd.DataFrame:
        '''è®¡ç®—æŒ¯å¹…'''

        return data['high'] / data['low'] - 1

    @staticmethod
    def _lamb_quantile(af_df: pd.DataFrame, lamb: int) -> pd.DataFrame:
        '''è·å–å¤§äºlmbçš„éƒ¨åˆ† 

        True/Falseè¡¨ç¤º Trueè¡¨ç¤ºå¤§äºlmbçš„éƒ¨åˆ†
        '''

        quantile = af_df.apply(lambda x: pd.qcut(
            x.rank(method='first'), 10, duplicates='drop', labels=list(range(1, 11))))

        return quantile == lmb

    @staticmethod
    def _lamb_split(af_df: pd.DataFrame, lamb: int) -> pd.DataFrame:

        return af_df.rank(pct=True) <= lamb

    def _sort_split(self, af_df: pd.DataFrame, **kwds) -> pd.DataFrame:
        '''æŒ‰æ’åè®¡ç®—

        True/Falseè¡¨ç¤º Trueè¡¨ç¤ºå¤§äºN/2çš„éƒ¨åˆ†
        '''

        return af_df.rank() > (self.max_window // 2)

    @property
    def name(self):

        return f'Ret{self.max_window-1}_{self.lamb}_momentum' if self.mod != 'sort' else f'Ret{self.max_window-1}_{self.group}_momentum'

class RPS(Factor):
    
    import warnings
    warnings.filterwarnings("ignore")

    name = 'RPS'
    max_window = 23
    dependencies = ['close']
    
    def calc(self, data)->pd.Series:
        
        close_df = data['close']
        pct_chg = close_df.pct_change().iloc[1:]
        rps = 1 - pct_chg.rank(axis=1).div(pct_chg.count(axis=1),axis=0)
        rps = rps.mean()
        
        return rps
        
'''å› å­å¤„ç†'''


def get_momentum_factor(gold_stocks: list, watch_date: str) -> pd.DataFrame:

    # æŒ¯å¹…å› å­ å‡åº
    af = AF_factor(gold_stocks, watch_date, 20)
    af.get_data()
    af_ser = af.v_factor(0.5)
    af_ser.name = 'AF'

    # èªæ˜é’±å› å­ é™åº
    q = Q_factor(gold_stocks, watch_date)
    q.get_data()
    q_ser = q.calc(0.5)
    q_ser.name = 'smart_q'

    # åŠ¨é‡ é™åº
    rm = RetN_momentum(gold_stocks, watch_date, 120)
    rm.get_data()
    rm_ser = rm.calc('lamb', 0.3)
    rm_ser.name = 'RM'

    return pd.concat((af_ser, q_ser, rm_ser), axis=1, sort=True)


def score_indicators(factor_df: pd.DataFrame, ind_direction: Union[bool, dict]) -> pd.DataFrame:
    '''å¯¹å› å­æ‰“åˆ†
    ind_direction:è®¾ç½®æ‰€æœ‰å› å­çš„æ’åºæ–¹å‘ï¼Œ'ascending'è¡¨ç¤ºå› å­å€¼è¶Šå¤§åˆ†æ•°è¶Šé«˜ï¼Œ'descending'è¡¨ç¤ºå› å­å€¼è¶Šå°åˆ†æ•°è¶Šé«˜ï¼›
    å½“ä¸ºdictæ—¶ï¼Œå¯ä»¥åˆ†åˆ«å¯¹ä¸åŒå› å­çš„æ’åºæ–¹å‘è¿›è¡Œè®¾ç½®
    '''

    if isinstance(ind_direction, bool):

        ind_direction = {col: ind_direction for col in factor_df.columns}

    return pd.concat((factor_df[col].rank(ascending=asc) for col, asc in ind_direction.items()), axis=1, sort=True)


'''ç»„åˆä¼˜åŒ–'''


def opt_pos_weight(securities: list, watch_date: Union[dt.date, str], window: int = 120, mod: str = False) -> pd.Series:
    '''è·å–å¯¹åº”çš„ç»„åˆä¼˜åŒ–æƒé‡'''

    if not mod:

        return None

    target_func = {'MaxSharpeRatio': MaxSharpeRatio(rf=0.03, weight_sum_equal=1.0, count=window),
                   'MaxProfit': MaxProfit(count=window),
                   'MinVariance': MinVariance(count=window),
                   'RiskParity': RiskParity(count=window, risk_budget=None)}

    return portfolio_optimizer(date=watch_date,
                               securities=securities,
                               target=target_func[mod],
                               constraints=WeightConstraint(
                                   low=0.3, high=1.0),
                               bounds=Bound(low=0.05, high=1.0))


'''äº¤æ˜“'''


def trade_func(context):

    # æ˜¯å¦ä½¿ç”¨å› å­
    if g.use_factor:

        securities = g.base_target['è‚¡ç¥¨ä»£ç '].unique().tolist()

        watch_date = context.previous_date

        
        score_df = composition_factors(securities,watch_date,g.in_week,12)

        # æ‰“åˆ†
        target = score_df['ç­‰æƒæ³•'].nlargest(g.handle_num).index.tolist()

    

    else:
        # è®¡ç®—æ¨èç‡
        nps_ser = get_net_promoter_score(g.base_target)
        target = nps_ser.nlargest(g.handle_num).index.tolist()

    # æ˜¯å¦è¿›è¡Œç»„åˆä¼˜åŒ–
    if g.optimizer_mod:
        optimized_weight = opt_pos_weight(
            target, context.previous_date, 120, g.optimizer_mod)

    else:

        optimized_weight = None

    # ä¼˜åŒ–å¤±è´¥ï¼Œç»™äºˆè­¦å‘Š
    if type(optimized_weight) == type(None):

        if g.optimizer_mod:
            print('è­¦å‘Šï¼šç»„åˆä¼˜åŒ–å¤±è´¥')

        order2list(context, target)

    else:

        order2dict(context, optimized_weight)


def get_target_securities(context) -> pd.DataFrame:
    '''è·å–å½“æœˆé‡‘è‚¡'''
    watch_date = time2str(context.previous_date, '%Y-%m')

    if watch_date in g.gold_stock_frame.index:

        g.base_target = g.gold_stock_frame.loc[watch_date]

    else:
        raise ValueError(f'æ•°æ®å‚¨å­˜{watch_date}ä¸åœ¨é‡‘è‚¡æ•°æ®ä¸­')
    



def order2dict(context, target_dict: dict) -> None:

    if not isinstance(target_dict, (dict, pd.Series)):
        raise ValueError('target_dictç±»å‹å¿…é¡»ä¸ºdict')

    # å…ˆå–å‡ºä¸åœ¨è‚¡ç¥¨æ± ä¸­çš„è‚¡ç¥¨
    for hold in context.portfolio.long_positions:

        if hold not in target_dict:

            order_target(hold, 0)

    total_value = context.portfolio.total_value

    for stock, w in target_dict.items():

        order_target_value(stock, w * total_value)  # è°ƒæ•´æ ‡çš„è‡³ç›®æ ‡æƒé‡


def order2list(context, target: list) -> None:

    if isinstance(target, str):

        target = [target]

    if target:

        # å…ˆå–å‡ºä¸åœ¨è‚¡ç¥¨æ± ä¸­çš„è‚¡ç¥¨
        for hold in context.portfolio.long_positions:

            if hold not in target:

                order_target(hold, 0)

        # ç­‰æƒæŒæœ‰
        veryStock = context.portfolio.total_value / len(target)

        for stock in target:

            order_target_value(stock, veryStock)
